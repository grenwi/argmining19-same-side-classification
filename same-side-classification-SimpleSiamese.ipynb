{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Clasiification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cross_path = 'data/cross-topic/{}.csv'\n",
    "data_within_path = 'data/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_train_df = pd.read_csv(data_cross_path.format('train_rand'), index_col='id', escapechar='\\\\')\n",
    "cross_dev_df = pd.read_csv(data_cross_path.format('dev_rand'), index_col='id', escapechar='\\\\')\n",
    "cross_test_df =  pd.read_csv(data_cross_path.format('test_rand'),index_col='id', escapechar='\\\\')\n",
    "\n",
    "within_train_df =  pd.read_csv(data_within_path.format('train_rand'), index_col='id', escapechar='\\\\')\n",
    "within_dev_df =  pd.read_csv(data_within_path.format('dev_rand'), index_col='id', escapechar='\\\\')\n",
    "within_test_df =  pd.read_csv(data_within_path.format('test_rand'), index_col='id', escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if title.find('abortion') > -1 :\n",
    "        row['tag'] = 'abortion'\n",
    "    elif title.find('gay marriage') > -1 :\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "cross_train_df = cross_train_df.apply(add_tag, axis=1)\n",
    "cross_dev_df = cross_dev_df.apply(add_tag, axis=1)\n",
    "cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "within_train_df = within_train_df.apply(add_tag, axis=1)\n",
    "within_dev_df = within_dev_df.apply(add_tag, axis=1)\n",
    "within_test_df = within_test_df.apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>accepted. pro may extend their arguments to th...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>i\"m pro-life. just think about it, your murder...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion (pro life)</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14632</th>\n",
       "      <td>ultrasounds fit well with pro-choice concepts.</td>\n",
       "      <td>475596d3-2019-04-17T11:47:21Z-00031-000</td>\n",
       "      <td>ultrasounds are a procedure any pregnant woman...</td>\n",
       "      <td>475596d3-2019-04-17T11:47:21Z-00031-000</td>\n",
       "      <td>475596d3-2019-04-17T11:47:21Z</td>\n",
       "      <td>True</td>\n",
       "      <td>mandatory ultrasounds before abortions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               argument1  \\\n",
       "id                                                         \n",
       "2607   accepted. pro may extend their arguments to th...   \n",
       "14632     ultrasounds fit well with pro-choice concepts.   \n",
       "\n",
       "                                  argument1_id  \\\n",
       "id                                               \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000   \n",
       "14632  475596d3-2019-04-17T11:47:21Z-00031-000   \n",
       "\n",
       "                                               argument2  \\\n",
       "id                                                         \n",
       "2607   i\"m pro-life. just think about it, your murder...   \n",
       "14632  ultrasounds are a procedure any pregnant woman...   \n",
       "\n",
       "                                  argument2_id                      debate_id  \\\n",
       "id                                                                              \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000  2a0d32eb-2019-04-18T11:46:44Z   \n",
       "14632  475596d3-2019-04-17T11:47:21Z-00031-000  475596d3-2019-04-17T11:47:21Z   \n",
       "\n",
       "       is_same_side                                   topic       tag  \n",
       "id                                                                     \n",
       "2607          False                     abortion (pro life)  abortion  \n",
       "14632          True  mandatory ultrasounds before abortions  abortion  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85249</th>\n",
       "      <td>gay marriage devalues marriage, frequency of o...</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>being unaccustomed to gay marriage is no argument</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z</td>\n",
       "      <td>False</td>\n",
       "      <td>gay marriage, debate on same sex marriage</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40696</th>\n",
       "      <td>fewer women would have abortions if they knew ...</td>\n",
       "      <td>b67fc3fb-2019-04-17T11:47:41Z-00192-000</td>\n",
       "      <td>poor women are disproportionately deprived cho...</td>\n",
       "      <td>b67fc3fb-2019-04-17T11:47:41Z-00192-000</td>\n",
       "      <td>b67fc3fb-2019-04-17T11:47:41Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               argument1  \\\n",
       "id                                                         \n",
       "85249  gay marriage devalues marriage, frequency of o...   \n",
       "40696  fewer women would have abortions if they knew ...   \n",
       "\n",
       "                                  argument1_id  \\\n",
       "id                                               \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000   \n",
       "40696  b67fc3fb-2019-04-17T11:47:41Z-00192-000   \n",
       "\n",
       "                                               argument2  \\\n",
       "id                                                         \n",
       "85249  being unaccustomed to gay marriage is no argument   \n",
       "40696  poor women are disproportionately deprived cho...   \n",
       "\n",
       "                                  argument2_id                      debate_id  \\\n",
       "id                                                                              \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000  d2f4b1cd-2019-04-17T11:47:27Z   \n",
       "40696  b67fc3fb-2019-04-17T11:47:41Z-00192-000  b67fc3fb-2019-04-17T11:47:41Z   \n",
       "\n",
       "       is_same_side                                      topic           tag  \n",
       "id                                                                            \n",
       "85249         False  gay marriage, debate on same sex marriage  gay marriage  \n",
       "40696          True                                   abortion      abortion  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>accepted. pro may extend their arguments to th...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>i\"m pro-life. just think about it, your murder...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion (pro life)</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14632</th>\n",
       "      <td>ultrasounds fit well with pro-choice concepts.</td>\n",
       "      <td>475596d3-2019-04-17T11:47:21Z-00031-000</td>\n",
       "      <td>ultrasounds are a procedure any pregnant woman...</td>\n",
       "      <td>475596d3-2019-04-17T11:47:21Z-00031-000</td>\n",
       "      <td>475596d3-2019-04-17T11:47:21Z</td>\n",
       "      <td>True</td>\n",
       "      <td>mandatory ultrasounds before abortions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               argument1  \\\n",
       "id                                                         \n",
       "2607   accepted. pro may extend their arguments to th...   \n",
       "14632     ultrasounds fit well with pro-choice concepts.   \n",
       "\n",
       "                                  argument1_id  \\\n",
       "id                                               \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000   \n",
       "14632  475596d3-2019-04-17T11:47:21Z-00031-000   \n",
       "\n",
       "                                               argument2  \\\n",
       "id                                                         \n",
       "2607   i\"m pro-life. just think about it, your murder...   \n",
       "14632  ultrasounds are a procedure any pregnant woman...   \n",
       "\n",
       "                                  argument2_id                      debate_id  \\\n",
       "id                                                                              \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000  2a0d32eb-2019-04-18T11:46:44Z   \n",
       "14632  475596d3-2019-04-17T11:47:21Z-00031-000  475596d3-2019-04-17T11:47:21Z   \n",
       "\n",
       "       is_same_side                                   topic       tag  \n",
       "id                                                                     \n",
       "2607          False                     abortion (pro life)  abortion  \n",
       "14632          True  mandatory ultrasounds before abortions  abortion  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85249</th>\n",
       "      <td>gay marriage devalues marriage, frequency of o...</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>being unaccustomed to gay marriage is no argument</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z</td>\n",
       "      <td>False</td>\n",
       "      <td>gay marriage, debate on same sex marriage</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40696</th>\n",
       "      <td>fewer women would have abortions if they knew ...</td>\n",
       "      <td>b67fc3fb-2019-04-17T11:47:41Z-00192-000</td>\n",
       "      <td>poor women are disproportionately deprived cho...</td>\n",
       "      <td>b67fc3fb-2019-04-17T11:47:41Z-00192-000</td>\n",
       "      <td>b67fc3fb-2019-04-17T11:47:41Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               argument1  \\\n",
       "id                                                         \n",
       "85249  gay marriage devalues marriage, frequency of o...   \n",
       "40696  fewer women would have abortions if they knew ...   \n",
       "\n",
       "                                  argument1_id  \\\n",
       "id                                               \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000   \n",
       "40696  b67fc3fb-2019-04-17T11:47:41Z-00192-000   \n",
       "\n",
       "                                               argument2  \\\n",
       "id                                                         \n",
       "85249  being unaccustomed to gay marriage is no argument   \n",
       "40696  poor women are disproportionately deprived cho...   \n",
       "\n",
       "                                  argument2_id                      debate_id  \\\n",
       "id                                                                              \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000  d2f4b1cd-2019-04-17T11:47:27Z   \n",
       "40696  b67fc3fb-2019-04-17T11:47:41Z-00192-000  b67fc3fb-2019-04-17T11:47:41Z   \n",
       "\n",
       "       is_same_side                                      topic           tag  \n",
       "id                                                                            \n",
       "85249         False  gay marriage, debate on same sex marriage  gay marriage  \n",
       "40696          True                                   abortion      abortion  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTify training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## within topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/gwiedemann/miniconda3/envs/nnnlp/lib/python3.6/site-packages/bert_serving/client/__init__.py:286: UserWarning: some of your sentences have more tokens than \"max_seq_len=256\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    }
   ],
   "source": [
    "a1 = bc.encode(within_train_df.argument1.tolist())\n",
    "a2 = bc.encode(within_train_df.argument2.tolist())\n",
    "train_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(train_embedded_pairs, open(\"BERT_pairs_train.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/gwiedemann/miniconda3/envs/nnnlp/lib/python3.6/site-packages/bert_serving/client/__init__.py:286: UserWarning: some of your sentences have more tokens than \"max_seq_len=256\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    }
   ],
   "source": [
    "a1 = bc.encode(within_dev_df.argument1.tolist())\n",
    "a2 = bc.encode(within_dev_df.argument2.tolist())\n",
    "dev_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(dev_embedded_pairs, open(\"BERT_pairs_dev.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/gwiedemann/miniconda3/envs/nnnlp/lib/python3.6/site-packages/bert_serving/client/__init__.py:286: UserWarning: some of your sentences have more tokens than \"max_seq_len=256\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    }
   ],
   "source": [
    "a1 = bc.encode(within_test_df.argument1.tolist())\n",
    "a2 = bc.encode(within_test_df.argument2.tolist())\n",
    "test_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(test_embedded_pairs, open(\"BERT_pairs_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model, clone_model, load_model\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *\n",
    "from keras import *\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import RandomUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_embs = pickle.load(open(\"BERT_pairs_train.pkl\",\"rb\"))\n",
    "dev_embs = pickle.load(open(\"BERT_pairs_dev.pkl\",\"rb\"))\n",
    "test_embs = pickle.load(open(\"BERT_pairs_test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57467, 1024)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, t2 = zip(*training_embs)\n",
    "train_args1 = np.array(t1)\n",
    "train_args2 = np.array(t2)\n",
    "train_args1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4498, 1024)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, t2 = zip(*dev_embs)\n",
    "dev_args1 = np.array(t1)\n",
    "dev_args2 = np.array(t2)\n",
    "dev_args1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1938, 1024)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, t2 = zip(*test_embs)\n",
    "test_args1 = np.array(t1)\n",
    "test_args2 = np.array(t2)\n",
    "test_args1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = [1 if t else 0 for t in within_train_df.is_same_side]\n",
    "dev_output = [1 if t else 0 for t in within_dev_df.is_same_side]\n",
    "test_output = [1 if t else 0 for t in within_test_df.is_same_side]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = t1[0].shape\n",
    "\n",
    "layer_input_1 = Input(shape = embedding_dims, name = 'input_1')\n",
    "layer_input_2 = Input(shape = embedding_dims, name = 'input_2')\n",
    "\n",
    "encoder_1 = Dense(embedding_dims[0], activation='relu')(layer_input_1)\n",
    "encoder_2 = Dense(embedding_dims[0], activation='relu')(layer_input_2)\n",
    "\n",
    "# combined_diff = subtract([encoder_1, encoder_2])\n",
    "# combined_mult = multiply([encoder_1, encoder_2])\n",
    "combined_dot = dot([encoder_1, encoder_2], axes=-1, normalize=False)\n",
    "combined_all = concatenate([encoder_1, encoder_2, combined_dot])\n",
    "\n",
    "features_pred = Dense(300, activation='relu')(combined_all)\n",
    "# features_norm = BatchNormalization()(features_pred)\n",
    "# features_acti = LeakyReLU()(features_pred)\n",
    "# features_drop = Dropout(rate=0.5)(features_acti)\n",
    "layer_prediction = Dense(1, activation='sigmoid')(features_pred)\n",
    "\n",
    "model = Model([layer_input_1, layer_input_2], layer_prediction)\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"argmining19_simple-nn-model.hdf5\", monitor='val_acc', \n",
    "                             verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57467 samples, validate on 4498 samples\n",
      "Epoch 1/20\n",
      "57467/57467 [==============================] - 14s 239us/step - loss: 0.1353 - acc: 0.9320 - val_loss: 0.3924 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.85838\n",
      "Epoch 2/20\n",
      "57467/57467 [==============================] - 13s 234us/step - loss: 0.1317 - acc: 0.9344 - val_loss: 0.4018 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85838 to 0.85860, saving model to argmining19_simple-nn-model.hdf5\n",
      "Epoch 3/20\n",
      "57467/57467 [==============================] - 14s 237us/step - loss: 0.1210 - acc: 0.9416 - val_loss: 0.4293 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85860 to 0.86372, saving model to argmining19_simple-nn-model.hdf5\n",
      "Epoch 4/20\n",
      "57467/57467 [==============================] - 13s 235us/step - loss: 0.1220 - acc: 0.9402 - val_loss: 0.4037 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.86372\n",
      "Epoch 5/20\n",
      "57467/57467 [==============================] - 13s 233us/step - loss: 0.1160 - acc: 0.9446 - val_loss: 0.4935 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.86372\n",
      "Epoch 6/20\n",
      "57467/57467 [==============================] - 14s 240us/step - loss: 0.1085 - acc: 0.9476 - val_loss: 0.4459 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.86372 to 0.86928, saving model to argmining19_simple-nn-model.hdf5\n",
      "Epoch 7/20\n",
      "57467/57467 [==============================] - 14s 236us/step - loss: 0.1049 - acc: 0.9498 - val_loss: 0.4687 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.86928\n",
      "Epoch 8/20\n",
      "57467/57467 [==============================] - 13s 234us/step - loss: 0.1085 - acc: 0.9500 - val_loss: 0.4719 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.86928\n",
      "Epoch 9/20\n",
      "57467/57467 [==============================] - 14s 237us/step - loss: 0.0963 - acc: 0.9546 - val_loss: 0.5017 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.86928\n",
      "Epoch 10/20\n",
      "57467/57467 [==============================] - 14s 236us/step - loss: 0.0937 - acc: 0.9557 - val_loss: 0.5042 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.86928\n",
      "Epoch 11/20\n",
      "57467/57467 [==============================] - 13s 233us/step - loss: 0.0967 - acc: 0.9557 - val_loss: 0.5434 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.86928\n",
      "Epoch 12/20\n",
      "57467/57467 [==============================] - 13s 229us/step - loss: 0.0933 - acc: 0.9583 - val_loss: 0.5508 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.86928\n",
      "Epoch 13/20\n",
      "57467/57467 [==============================] - 14s 238us/step - loss: 0.0854 - acc: 0.9604 - val_loss: 0.5667 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.86928\n",
      "Epoch 14/20\n",
      "57467/57467 [==============================] - 14s 239us/step - loss: 0.0831 - acc: 0.9624 - val_loss: 0.5559 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.86928\n",
      "Epoch 15/20\n",
      "57467/57467 [==============================] - 13s 235us/step - loss: 0.0834 - acc: 0.9627 - val_loss: 0.5842 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.86928\n",
      "Epoch 16/20\n",
      " 5440/57467 [=>............................] - ETA: 12s - loss: 0.0676 - acc: 0.9691"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e4d340c69ca0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit([train_args1, train_args2], train_output, batch_size=32, epochs=20, \n\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_args1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_args2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           callbacks=[checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/nnnlp/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/nnnlp/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    185\u001b[0m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m~/miniconda3/envs/nnnlp/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nnnlp/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([train_args1, train_args2], train_output, batch_size=32, epochs=30, \n",
    "          validation_data=([dev_args1, dev_args2], dev_output), verbose=True,\n",
    "          callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"argmining19_simple-nn-model.hdf5\")\n",
    "dev_output_pred = np.round(model.predict([dev_args1, dev_args2]))\n",
    "dev_output_pred = np.round(model.predict([dev_args1, dev_args2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev set performances\n",
    "# --------------------\n",
    "\n",
    "# concatenate([encoder_1, encoder_2, combined_diff, combined_dot])\n",
    "# Epoch 17/20\n",
    "# 57512/57512 [==============================] - 12s 207us/step - loss: 0.1906 - acc: 0.8963 - val_loss: 0.3081 - val_acc: 0.8512\n",
    "\n",
    "# combined_all = concatenate([encoder_1, encoder_2])\n",
    "# Epoch 17/20\n",
    "# 57512/57512 [==============================] - 11s 191us/step - loss: 0.1767 - acc: 0.9052 - val_loss: 0.3394 - val_acc: 0.8514\n",
    "\n",
    "# combined_all = concatenate([encoder_1, encoder_2, combined_dot])\n",
    "# Epoch 17/20\n",
    "# 57512/57512 [==============================] - 12s 205us/step - loss: 0.1726 - acc: 0.9115 - val_loss: 0.3162 - val_acc: 0.8559\n",
    "\n",
    "# + dropout 0.1: h√ºlft nicht viel... bzw. nichts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score, f1_score\n",
    "def report_training_results(y_test, y_pred):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))  \n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2))  #\n",
    "    print()\n",
    "\n",
    "    print('Report:')\n",
    "    print(classification_report(y_test, y_pred))  \n",
    "    f1_dic = {}\n",
    "    \n",
    "    f1_dic['macro'] = round(f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1754  304]\n",
      " [ 284 2156]]\n",
      "\n",
      "Accuracy:  0.87\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.86      2058\n",
      "          1       0.88      0.88      0.88      2440\n",
      "\n",
      "avg / total       0.87      0.87      0.87      4498\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'macro': 0.87, 'micro': 0.87}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set performance\n",
    "report_training_results(dev_output, test_output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
