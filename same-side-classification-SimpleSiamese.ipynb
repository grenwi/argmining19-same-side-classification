{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cross_path = '../argmining19-same-side-classification/data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = '../argmining19-same-side-classification/data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model, clone_model, load_model\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *\n",
    "from keras import *\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import RandomUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score, f1_score\n",
    "def report_training_results(y_test, y_pred):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))  \n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2))  #\n",
    "    print()\n",
    "\n",
    "    print('Report:')\n",
    "    print(classification_report(y_test, y_pred))  \n",
    "    f1_dic = {}\n",
    "    \n",
    "    f1_dic['macro'] = round(f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../argmining19-same-side-classification/data/same-side-classification/cross-topic/training.csv\n",
      "../argmining19-same-side-classification/data/same-side-classification/cross-topic/test.csv\n",
      "../argmining19-same-side-classification/data/same-side-classification/within-topic/training.csv\n",
      "../argmining19-same-side-classification/data/same-side-classification/within-topic/test.csv\n"
     ]
    }
   ],
   "source": [
    "print(data_cross_path.format('training'))\n",
    "cross_train_df = pd.read_csv(data_cross_path.format('training'),\n",
    "                                quotechar='\"',\n",
    "                                quoting=csv.QUOTE_ALL,\n",
    "                                encoding='utf-8',\n",
    "                                escapechar='\\\\',\n",
    "                                doublequote=False,\n",
    "                                index_col='id')\n",
    "print(data_cross_path.format('test'))\n",
    "cross_test_df = pd.read_csv(data_cross_path.format('test'),\n",
    "                            # quotechar='\"',\n",
    "                            # quoting=csv.QUOTE_ALL,\n",
    "                            # encoding='utf-8',\n",
    "                            # escapechar='\\\\',\n",
    "                            # doublequote=False,\n",
    "                            index_col='id')\n",
    "\n",
    "print(data_within_path.format('training'))\n",
    "within_train_df = pd.read_csv(data_within_path.format('training'),\n",
    "                                 quotechar='\"',\n",
    "                                 quoting=csv.QUOTE_ALL,\n",
    "                                 encoding='utf-8',\n",
    "                                 escapechar='\\\\',\n",
    "                                 doublequote=False,\n",
    "                                 index_col='id')\n",
    "print(data_within_path.format('test'))\n",
    "within_test_df = pd.read_csv(data_within_path.format('test'),\n",
    "                             quotechar='\"',\n",
    "                             # quoting=csv.QUOTE_ALL,\n",
    "                             # encoding='utf-8',\n",
    "                             # escapechar='\\\\',\n",
    "                             # doublequote=False,\n",
    "                             index_col='id')\n",
    "\n",
    "\n",
    "within_dev_df = pd.read_csv(\"data/within-topic/dev_rand.csv\",\n",
    "                             quotechar='\"',\n",
    "                             # quoting=csv.QUOTE_ALL,\n",
    "                             # encoding='utf-8',\n",
    "                             escapechar='\\\\',\n",
    "                             # doublequote=False,\n",
    "                             index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if title.find('abortion') > -1 :\n",
    "        row['tag'] = 'abortion'\n",
    "    elif title.find('gay marriage') > -1 :\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "cross_train_df = cross_train_df.apply(add_tag, axis=1)\n",
    "# cross_dev_df = cross_dev_df.apply(add_tag, axis=1)\n",
    "cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "within_train_df = within_train_df.apply(add_tag, axis=1)\n",
    "within_dev_df = within_dev_df.apply(add_tag, axis=1)\n",
    "within_test_df = within_test_df.apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are two reasons why this debate should g...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>i will give my opponent a chance to respond.</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there are two reasons why this debate should g...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>in this debate, there are a few factors that m...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            argument1  \\\n",
       "id                                                      \n",
       "0   there are two reasons why this debate should g...   \n",
       "1   there are two reasons why this debate should g...   \n",
       "\n",
       "                               argument1_id  \\\n",
       "id                                            \n",
       "0   100c174f-2019-04-18T17:33:51Z-00000-000   \n",
       "1   100c174f-2019-04-18T17:33:51Z-00000-000   \n",
       "\n",
       "                                            argument2  \\\n",
       "id                                                      \n",
       "0        i will give my opponent a chance to respond.   \n",
       "1   in this debate, there are a few factors that m...   \n",
       "\n",
       "                               argument2_id                      debate_id  \\\n",
       "id                                                                           \n",
       "0   100c174f-2019-04-18T17:33:51Z-00000-000  100c174f-2019-04-18T17:33:51Z   \n",
       "1   100c174f-2019-04-18T17:33:51Z-00000-000  100c174f-2019-04-18T17:33:51Z   \n",
       "\n",
       "    is_same_side                                       topic       tag  \n",
       "id                                                                      \n",
       "0           True  abortion should be illegal with exceptions  abortion  \n",
       "1           True  abortion should be illegal with exceptions  abortion  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i would like to start off by thanking my oppon...</td>\n",
       "      <td>i was hoping that since this member took the t...</td>\n",
       "      <td>gay marriage is wrong</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i would like to start off by thanking my oppon...</td>\n",
       "      <td>hello, i am new to this website and usually de...</td>\n",
       "      <td>gay marriage is wrong</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            argument1  \\\n",
       "id                                                      \n",
       "0   i would like to start off by thanking my oppon...   \n",
       "1   i would like to start off by thanking my oppon...   \n",
       "\n",
       "                                            argument2                  topic  \\\n",
       "id                                                                             \n",
       "0   i was hoping that since this member took the t...  gay marriage is wrong   \n",
       "1   hello, i am new to this website and usually de...  gay marriage is wrong   \n",
       "\n",
       "             tag  \n",
       "id                \n",
       "0   gay marriage  \n",
       "1   gay marriage  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85249</th>\n",
       "      <td>gay marriage devalues marriage, frequency of o...</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>being unaccustomed to gay marriage is no argument</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z</td>\n",
       "      <td>False</td>\n",
       "      <td>gay marriage, debate on same sex marriage</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>accepted. pro may extend their arguments to th...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>i\"m pro-life. just think about it, your murder...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion (pro life)</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               argument1  \\\n",
       "id                                                         \n",
       "85249  gay marriage devalues marriage, frequency of o...   \n",
       "2607   accepted. pro may extend their arguments to th...   \n",
       "\n",
       "                                  argument1_id  \\\n",
       "id                                               \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000   \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000   \n",
       "\n",
       "                                               argument2  \\\n",
       "id                                                         \n",
       "85249  being unaccustomed to gay marriage is no argument   \n",
       "2607   i\"m pro-life. just think about it, your murder...   \n",
       "\n",
       "                                  argument2_id                      debate_id  \\\n",
       "id                                                                              \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000  d2f4b1cd-2019-04-17T11:47:27Z   \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000  2a0d32eb-2019-04-18T11:46:44Z   \n",
       "\n",
       "       is_same_side                                      topic           tag  \n",
       "id                                                                            \n",
       "85249         False  gay marriage, debate on same sex marriage  gay marriage  \n",
       "2607          False                        abortion (pro life)      abortion  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i would like to start off by thanking my oppon...</td>\n",
       "      <td>hello, i am new to this website and usually de...</td>\n",
       "      <td>gay marriage is wrong</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>don't judge a book by its cover. you neef obje...</td>\n",
       "      <td>the bible has multiple versions so you can't s...</td>\n",
       "      <td>gay marriage is wrong</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            argument1  \\\n",
       "id                                                      \n",
       "11  i would like to start off by thanking my oppon...   \n",
       "20  don't judge a book by its cover. you neef obje...   \n",
       "\n",
       "                                            argument2                  topic  \\\n",
       "id                                                                             \n",
       "11  hello, i am new to this website and usually de...  gay marriage is wrong   \n",
       "20  the bible has multiple versions so you can't s...  gay marriage is wrong   \n",
       "\n",
       "             tag  \n",
       "id                \n",
       "11  gay marriage  \n",
       "20  gay marriage  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def get_train_test_sets(df, ratio=0.30, random_state=1):\n",
    "    X = df[['argument1', 'argument2', 'argument1_id', 'argument2_id', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=ratio,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Within topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTify training and test data\n",
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = get_train_test_sets(within_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rioreiser/miniconda3/envs/sameside/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=256\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    }
   ],
   "source": [
    "a1 = bc.encode(X_train.argument1.tolist())\n",
    "a2 = bc.encode(X_train.argument2.tolist())\n",
    "train_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(train_embedded_pairs, open(\"BERT_pairs_train.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = bc.encode(X_dev.argument1.tolist())\n",
    "a2 = bc.encode(X_dev.argument2.tolist())\n",
    "dev_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(dev_embedded_pairs, open(\"BERT_pairs_dev.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = bc.encode(within_test_df.argument1.tolist())\n",
    "a2 = bc.encode(within_test_df.argument2.tolist())\n",
    "test_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(test_embedded_pairs, open(\"BERT_pairs_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_embs = pickle.load(open(\"BERT_pairs_train.pkl\",\"rb\"))\n",
    "dev_embs = pickle.load(open(\"BERT_pairs_dev.pkl\",\"rb\"))\n",
    "test_embs = pickle.load(open(\"BERT_pairs_test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57467, 1024)\n"
     ]
    }
   ],
   "source": [
    "t1, t2 = zip(*training_embs)\n",
    "train_args1 = np.array(t1)\n",
    "train_args2 = np.array(t2)\n",
    "print(train_args1.shape)\n",
    "train_tags = to_categorical([0 if t=='abortion' else 1 for t in within_train_df.tag.tolist()], num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'within_dev_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b88c06fea01d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdev_args1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdev_args2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdev_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'abortion'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwithin_dev_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdev_args1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'within_dev_df' is not defined"
     ]
    }
   ],
   "source": [
    "t1, t2 = zip(*dev_embs)\n",
    "dev_args1 = np.array(t1)\n",
    "dev_args2 = np.array(t2)\n",
    "dev_tags = to_categorical([0 if t=='abortion' else 1 for t in within_dev_df.tag.tolist()], num_classes=2)\n",
    "dev_args1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1938, 1024)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, t2 = zip(*test_embs)\n",
    "test_args1 = np.array(t1)\n",
    "test_args2 = np.array(t2)\n",
    "test_tags = to_categorical([0 if t=='abortion' else 1 for t in within_test_df.tag.tolist()], num_classes=2)\n",
    "test_args1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = [1 if t else 0 for t in within_train_df.is_same_side]\n",
    "# dev_output = [1 if t else 0 for t in within_dev_df.is_same_side]\n",
    "# test_output = [1 if t else 0 for t in within_test_df.is_same_side]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import _Merge\n",
    "\n",
    "def subtract_abs(inputs, **kwargs):\n",
    "    return SubtractAbs(**kwargs)(inputs)\n",
    "\n",
    "class SubtractAbs(_Merge):\n",
    "    def build(self, input_shape):\n",
    "        super(SubtractAbs, self).build(input_shape)\n",
    "        if len(input_shape) != 2:\n",
    "            raise ValueError('A `SubtractAbs` layer should be called '\n",
    "                             'on exactly 2 inputs')\n",
    "\n",
    "    def _merge_function(self, inputs):\n",
    "        if len(inputs) != 2:\n",
    "            raise ValueError('A `SubtractAbs` layer should be called '\n",
    "                             'on exactly 2 inputs')\n",
    "        return K.abs(inputs[0] - inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = t1[0].shape\n",
    "\n",
    "layer_input_1 = Input(shape = embedding_dims, name = 'input_1')\n",
    "layer_input_2 = Input(shape = embedding_dims, name = 'input_2')\n",
    "# layer_input_3 = Input(shape = (2,), name = 'input_3')\n",
    "\n",
    "encoder_1 = Dense(embedding_dims[0], activation='relu')(layer_input_1)\n",
    "encoder_2 = Dense(embedding_dims[0], activation='relu')(layer_input_2)\n",
    "\n",
    "combined_diff = subtract_abs([encoder_1, encoder_2])\n",
    "# combined_mult = multiply([encoder_1, encoder_2])\n",
    "combined_dot = dot([encoder_1, encoder_2], axes=-1, normalize=False)\n",
    "combined_all = concatenate([encoder_1, encoder_2, combined_diff])\n",
    "\n",
    "features_pred = Dense(300, activation='relu')(combined_all)\n",
    "# features_norm = BatchNormalization()(features_pred)\n",
    "# features_acti = LeakyReLU()(features_pred)\n",
    "# features_drop = Dropout(rate=0.5)(features_acti)\n",
    "layer_prediction = Dense(1, activation='sigmoid')(features_pred)\n",
    "\n",
    "model = Model([layer_input_1, layer_input_2], layer_prediction)\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"argmining19_simple-nn-model.hdf5\", monitor='val_acc', \n",
    "                             verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_tags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-1bb9c8f38b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit([train_args1, train_args2, train_tags], train_output, batch_size=32, epochs=50, \n\u001b[0;32m----> 2\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_args1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_args2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_tags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m           callbacks=[checkpoint])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_tags' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit([train_args1, train_args2, train_tags], train_output, batch_size=32, epochs=50, \n",
    "          validation_data=([dev_args1, dev_args2, dev_tags], dev_output), verbose=True,\n",
    "          callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"argmining19_simple-nn-model.hdf5\")\n",
    "dev_output_pred = np.round(model.predict([dev_args1, dev_args2, dev_tags]))\n",
    "test_output_pred = np.round(model.predict([test_args1, test_args2, test_tags]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev set performances\n",
    "# --------------------\n",
    "\n",
    "# concatenate([encoder_1, encoder_2, combined_diff, combined_dot])\n",
    "# Epoch 17/20\n",
    "# 57512/57512 [==============================] - 12s 207us/step - loss: 0.1906 - acc: 0.8963 - val_loss: 0.3081 - val_acc: 0.8512\n",
    "\n",
    "# combined_all = concatenate([encoder_1, encoder_2])\n",
    "# Epoch 17/20\n",
    "# 57512/57512 [==============================] - 11s 191us/step - loss: 0.1767 - acc: 0.9052 - val_loss: 0.3394 - val_acc: 0.8514\n",
    "\n",
    "# combined_all = concatenate([encoder_1, encoder_2, combined_dot])\n",
    "# Epoch 17/20\n",
    "# 57512/57512 [==============================] - 12s 205us/step - loss: 0.1726 - acc: 0.9115 - val_loss: 0.3162 - val_acc: 0.8559\n",
    "\n",
    "# + dropout 0.1: h√ºlft nicht viel... bzw. nichts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1752  306]\n",
      " [ 296 2144]]\n",
      "\n",
      "Accuracy:  0.87\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      2058\n",
      "          1       0.88      0.88      0.88      2440\n",
      "\n",
      "avg / total       0.87      0.87      0.87      4498\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'macro': 0.87, 'micro': 0.87}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev set performance\n",
    "report_training_results(dev_output, dev_output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[794 114]\n",
      " [128 902]]\n",
      "\n",
      "Accuracy:  0.88\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.87      0.87       908\n",
      "          1       0.89      0.88      0.88      1030\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1938\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'macro': 0.87, 'micro': 0.88}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set performance\n",
    "report_training_results(test_output, test_output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1049600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1049600     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2051)         0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dot_1[0][0]                      \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          615600      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            301         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,715,101\n",
      "Trainable params: 2,715,101\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test set probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_test_all =  pd.read_csv(\"data/same-side-classification/within-topic/test.csv\", index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95327</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95345</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95364</th>\n",
       "      <td>gay marriage should be legalized in america i'...</td>\n",
       "      <td>gay marriage should be legalized in america i ...</td>\n",
       "      <td>gay marriage should be legalized in america</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95369</th>\n",
       "      <td>every human being has rights, even if they can...</td>\n",
       "      <td>first, i must say that i do not under any circ...</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95370</th>\n",
       "      <td>yes, but the baby is still not alive, it is st...</td>\n",
       "      <td>until a baby is born naturally, it is not trul...</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               argument1  \\\n",
       "id                                                         \n",
       "95327  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "95345  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "95364  gay marriage should be legalized in america i'...   \n",
       "95369  every human being has rights, even if they can...   \n",
       "95370  yes, but the baby is still not alive, it is st...   \n",
       "\n",
       "                                               argument2  \\\n",
       "id                                                         \n",
       "95327  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "95345  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "95364  gay marriage should be legalized in america i ...   \n",
       "95369  first, i must say that i do not under any circ...   \n",
       "95370  until a baby is born naturally, it is not trul...   \n",
       "\n",
       "                                                   topic           tag  \n",
       "id                                                                      \n",
       "95327  (resolved)on balance:middleclassandrichwomenwh...      abortion  \n",
       "95345  (resolved)on balance:middleclassandrichwomenwh...      abortion  \n",
       "95364        gay marriage should be legalized in america  gay marriage  \n",
       "95369           live birth abortion should stay illegal.      abortion  \n",
       "95370           live birth abortion should stay illegal.      abortion  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_test_all = within_test_all.apply(add_tag, axis=1)\n",
    "within_test_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3c130ca99d2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwithin_test_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margument1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwithin_test_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margument2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtestall_embedded_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestall_embedded_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BERT_pairs_testall.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bc' is not defined"
     ]
    }
   ],
   "source": [
    "a1 = bc.encode(within_test_all.argument1.tolist())\n",
    "a2 = bc.encode(within_test_all.argument2.tolist())\n",
    "testall_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(testall_embedded_pairs, open(\"BERT_pairs_testall.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testall_embs = pickle.load(open(\"BERT_pairs_testall.pkl\",\"rb\"))\n",
    "t1, t2 = zip(*testall_embs)\n",
    "testall_args1 = np.array(t1)\n",
    "testall_args2 = np.array(t2)\n",
    "testall_args1.shape\n",
    "testall_tags = to_categorical([0 if t=='abortion' else 1 for t in within_train_df.tag.tolist()], num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"argmining19_simple-nn-model.hdf5\")\n",
    "testall_output_pred = model.predict([testall_args1, testall_args2, testall_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to disk\n",
    "with open(\"predicted_labels_simple-nn_within.csv\", \"w\") as f:\n",
    "    for i, a in enumerate(testall_output_pred):\n",
    "        f.write(str(within_test_all.index.values[i]) + \",\" + str(a[0]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67102396],\n",
       "       [0.6054134 ],\n",
       "       [0.9379481 ],\n",
       "       ...,\n",
       "       [0.6328175 ],\n",
       "       [0.63011324],\n",
       "       [0.02002504]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testall_output_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_dev_df = within_train_df[within_train_df.tag == \"gay marriage\"][:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cross_dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/gwiedemann/miniconda3/envs/nnnlp/lib/python3.6/site-packages/bert_serving/client/__init__.py:286: UserWarning: some of your sentences have more tokens than \"max_seq_len=256\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    }
   ],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()\n",
    "# dev set\n",
    "a1 = bc.encode(cross_dev_df.argument1.tolist())\n",
    "a2 = bc.encode(cross_dev_df.argument2.tolist())\n",
    "dev_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(dev_embedded_pairs, open(\"BERT_pairs_cross_dev.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are two reasons why this debate should g...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>i will give my opponent a chance to respond.</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there are two reasons why this debate should g...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>in this debate, there are a few factors that m...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first i want to thank my opponent for letting ...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00001-000</td>\n",
       "      <td>this is my first debate so please just bare wi...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00001-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i will give my opponent a chance to respond.</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00002-000</td>\n",
       "      <td>in this debate, there are a few factors that m...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00002-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there are two reasons why this debate should g...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>first i want to thank my opponent for letting ...</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z-00000-000</td>\n",
       "      <td>100c174f-2019-04-18T17:33:51Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion should be illegal with exceptions</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            argument1  \\\n",
       "id                                                      \n",
       "0   there are two reasons why this debate should g...   \n",
       "1   there are two reasons why this debate should g...   \n",
       "2   first i want to thank my opponent for letting ...   \n",
       "3        i will give my opponent a chance to respond.   \n",
       "4   there are two reasons why this debate should g...   \n",
       "\n",
       "                               argument1_id  \\\n",
       "id                                            \n",
       "0   100c174f-2019-04-18T17:33:51Z-00000-000   \n",
       "1   100c174f-2019-04-18T17:33:51Z-00000-000   \n",
       "2   100c174f-2019-04-18T17:33:51Z-00001-000   \n",
       "3   100c174f-2019-04-18T17:33:51Z-00002-000   \n",
       "4   100c174f-2019-04-18T17:33:51Z-00000-000   \n",
       "\n",
       "                                            argument2  \\\n",
       "id                                                      \n",
       "0        i will give my opponent a chance to respond.   \n",
       "1   in this debate, there are a few factors that m...   \n",
       "2   this is my first debate so please just bare wi...   \n",
       "3   in this debate, there are a few factors that m...   \n",
       "4   first i want to thank my opponent for letting ...   \n",
       "\n",
       "                               argument2_id                      debate_id  \\\n",
       "id                                                                           \n",
       "0   100c174f-2019-04-18T17:33:51Z-00000-000  100c174f-2019-04-18T17:33:51Z   \n",
       "1   100c174f-2019-04-18T17:33:51Z-00000-000  100c174f-2019-04-18T17:33:51Z   \n",
       "2   100c174f-2019-04-18T17:33:51Z-00001-000  100c174f-2019-04-18T17:33:51Z   \n",
       "3   100c174f-2019-04-18T17:33:51Z-00002-000  100c174f-2019-04-18T17:33:51Z   \n",
       "4   100c174f-2019-04-18T17:33:51Z-00000-000  100c174f-2019-04-18T17:33:51Z   \n",
       "\n",
       "    is_same_side                                       topic       tag  \n",
       "id                                                                      \n",
       "0           True  abortion should be illegal with exceptions  abortion  \n",
       "1           True  abortion should be illegal with exceptions  abortion  \n",
       "2           True  abortion should be illegal with exceptions  abortion  \n",
       "3           True  abortion should be illegal with exceptions  abortion  \n",
       "4          False  abortion should be illegal with exceptions  abortion  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/gwiedemann/miniconda3/envs/nnnlp/lib/python3.6/site-packages/bert_serving/client/__init__.py:286: UserWarning: some of your sentences have more tokens than \"max_seq_len=256\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    }
   ],
   "source": [
    "# BERTify training and test data\n",
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()\n",
    "# train set\n",
    "a1 = bc.encode(cross_train_df.argument1.tolist())\n",
    "a2 = bc.encode(cross_train_df.argument2.tolist())\n",
    "train_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(train_embedded_pairs, open(\"BERT_pairs_cross_train.pkl\", \"wb\"))\n",
    "# dev set\n",
    "a1 = bc.encode(cross_dev_df.argument1.tolist())\n",
    "a2 = bc.encode(cross_dev_df.argument2.tolist())\n",
    "dev_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(dev_embedded_pairs, open(\"BERT_pairs_cross_dev.pkl\", \"wb\"))\n",
    "# test set\n",
    "a1 = bc.encode(cross_test_df.argument1.tolist())\n",
    "a2 = bc.encode(cross_test_df.argument2.tolist())\n",
    "test_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(test_embedded_pairs, open(\"BERT_pairs_cross_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_embs = pickle.load(open(\"BERT_pairs_cross_train.pkl\",\"rb\"))\n",
    "dev_embs = pickle.load(open(\"BERT_pairs_cross_dev.pkl\",\"rb\"))\n",
    "test_embs = pickle.load(open(\"BERT_pairs_cross_test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "t1, t2 = zip(*training_embs)\n",
    "train_args1 = np.array(t1)\n",
    "train_args2 = np.array(t2)\n",
    "# dev set\n",
    "t1, t2 = zip(*dev_embs)\n",
    "dev_args1 = np.array(t1)\n",
    "dev_args2 = np.array(t2)\n",
    "# test set\n",
    "t1, t2 = zip(*test_embs)\n",
    "test_args1 = np.array(t1)\n",
    "test_args2 = np.array(t2)\n",
    "# outputs\n",
    "train_output = [1 if t else 0 for t in cross_train_df.is_same_side]\n",
    "dev_output = [1 if t else 0 for t in cross_dev_df.is_same_side]\n",
    "test_output = [1 if t else 0 for t in cross_test_df.is_same_side]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model\n",
    "embedding_dims = t1[0].shape\n",
    "\n",
    "layer_input_1 = Input(shape = embedding_dims, name = 'input_1')\n",
    "layer_input_2 = Input(shape = embedding_dims, name = 'input_2')\n",
    "\n",
    "encoder_1 = Dense(embedding_dims[0], activation='relu')(layer_input_1)\n",
    "encoder_2 = Dense(embedding_dims[0], activation='relu')(layer_input_2)\n",
    "combined_dot = dot([encoder_1, encoder_2], axes=-1, normalize=False)\n",
    "combined_all = concatenate([encoder_1, encoder_2, combined_dot])\n",
    "\n",
    "features_pred = Dense(300, activation='relu')(combined_all)\n",
    "layer_prediction = Dense(1, activation='sigmoid')(features_pred)\n",
    "\n",
    "model = Model([layer_input_1, layer_input_2], layer_prediction)\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54947 samples, validate on 3000 samples\n",
      "Epoch 1/30\n",
      "54947/54947 [==============================] - 15s 275us/step - loss: 0.3754 - acc: 0.7774 - val_loss: 1.1004 - val_acc: 0.6043\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.60433, saving model to argmining19_simple-nn-model_cross.hdf5\n",
      "Epoch 2/30\n",
      "54947/54947 [==============================] - 12s 217us/step - loss: 0.3018 - acc: 0.8125 - val_loss: 1.1684 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.60433\n",
      "Epoch 3/30\n",
      "54947/54947 [==============================] - 12s 212us/step - loss: 0.2849 - acc: 0.8248 - val_loss: 1.8151 - val_acc: 0.6057\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.60433 to 0.60567, saving model to argmining19_simple-nn-model_cross.hdf5\n",
      "Epoch 4/30\n",
      "54947/54947 [==============================] - 12s 213us/step - loss: 0.2708 - acc: 0.8344 - val_loss: 1.6992 - val_acc: 0.5933\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.60567\n",
      "Epoch 5/30\n",
      "54947/54947 [==============================] - 12s 211us/step - loss: 0.2611 - acc: 0.8420 - val_loss: 1.6905 - val_acc: 0.5790\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.60567\n",
      "Epoch 6/30\n",
      "54947/54947 [==============================] - 12s 211us/step - loss: 0.2540 - acc: 0.8491 - val_loss: 1.9085 - val_acc: 0.6067\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.60567 to 0.60667, saving model to argmining19_simple-nn-model_cross.hdf5\n",
      "Epoch 7/30\n",
      "54947/54947 [==============================] - 12s 213us/step - loss: 0.2474 - acc: 0.8537 - val_loss: 1.9167 - val_acc: 0.6083\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.60667 to 0.60833, saving model to argmining19_simple-nn-model_cross.hdf5\n",
      "Epoch 8/30\n",
      "54947/54947 [==============================] - 12s 217us/step - loss: 0.2392 - acc: 0.8611 - val_loss: 2.2926 - val_acc: 0.5813\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.60833\n",
      "Epoch 9/30\n",
      "54947/54947 [==============================] - 12s 217us/step - loss: 0.2299 - acc: 0.8692 - val_loss: 2.0929 - val_acc: 0.5937\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.60833\n",
      "Epoch 10/30\n",
      "54947/54947 [==============================] - 12s 216us/step - loss: 0.2221 - acc: 0.8757 - val_loss: 2.2617 - val_acc: 0.5967\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.60833\n",
      "Epoch 11/30\n",
      "54947/54947 [==============================] - 12s 219us/step - loss: 0.2124 - acc: 0.8809 - val_loss: 2.5313 - val_acc: 0.5880\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.60833\n",
      "Epoch 12/30\n",
      "54947/54947 [==============================] - 12s 214us/step - loss: 0.2057 - acc: 0.8889 - val_loss: 2.3829 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.60833\n",
      "Epoch 13/30\n",
      "54947/54947 [==============================] - 12s 218us/step - loss: 0.1947 - acc: 0.8937 - val_loss: 2.9677 - val_acc: 0.5853\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.60833\n",
      "Epoch 14/30\n",
      "54947/54947 [==============================] - 12s 213us/step - loss: 0.1891 - acc: 0.8982 - val_loss: 2.7678 - val_acc: 0.5920\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.60833\n",
      "Epoch 15/30\n",
      "54947/54947 [==============================] - 12s 212us/step - loss: 0.1784 - acc: 0.9045 - val_loss: 2.7547 - val_acc: 0.6080\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.60833\n",
      "Epoch 16/30\n",
      "54947/54947 [==============================] - 12s 210us/step - loss: 0.1735 - acc: 0.9095 - val_loss: 2.9664 - val_acc: 0.5863\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.60833\n",
      "Epoch 17/30\n",
      "54947/54947 [==============================] - 12s 212us/step - loss: 0.1693 - acc: 0.9122 - val_loss: 2.8665 - val_acc: 0.5967\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.60833\n",
      "Epoch 18/30\n",
      "54947/54947 [==============================] - 12s 211us/step - loss: 0.1565 - acc: 0.9200 - val_loss: 3.0456 - val_acc: 0.5980\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.60833\n",
      "Epoch 19/30\n",
      "54947/54947 [==============================] - 12s 210us/step - loss: 0.1532 - acc: 0.9223 - val_loss: 2.9573 - val_acc: 0.5867\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.60833\n",
      "Epoch 20/30\n",
      "54947/54947 [==============================] - 12s 213us/step - loss: 0.1452 - acc: 0.9274 - val_loss: 3.2567 - val_acc: 0.6033\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.60833\n",
      "Epoch 21/30\n",
      "54947/54947 [==============================] - 12s 221us/step - loss: 0.1389 - acc: 0.9312 - val_loss: 3.1779 - val_acc: 0.5953\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.60833\n",
      "Epoch 22/30\n",
      "54947/54947 [==============================] - 13s 245us/step - loss: 0.1329 - acc: 0.9340 - val_loss: 3.4378 - val_acc: 0.5813\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.60833\n",
      "Epoch 23/30\n",
      "54947/54947 [==============================] - 12s 216us/step - loss: 0.1301 - acc: 0.9381 - val_loss: 3.1643 - val_acc: 0.5960\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.60833\n",
      "Epoch 24/30\n",
      "54947/54947 [==============================] - 12s 213us/step - loss: 0.1207 - acc: 0.9414 - val_loss: 3.5160 - val_acc: 0.5760\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.60833\n",
      "Epoch 25/30\n",
      "54947/54947 [==============================] - 12s 216us/step - loss: 0.1153 - acc: 0.9448 - val_loss: 3.6038 - val_acc: 0.5893\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.60833\n",
      "Epoch 26/30\n",
      "54947/54947 [==============================] - 12s 212us/step - loss: 0.1183 - acc: 0.9447 - val_loss: 3.5143 - val_acc: 0.5957\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.60833\n",
      "Epoch 27/30\n",
      "54947/54947 [==============================] - 12s 214us/step - loss: 0.1054 - acc: 0.9496 - val_loss: 3.5343 - val_acc: 0.5773\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.60833\n",
      "Epoch 28/30\n",
      "54947/54947 [==============================] - 12s 215us/step - loss: 0.1008 - acc: 0.9520 - val_loss: 3.5969 - val_acc: 0.5723\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.60833\n",
      "Epoch 29/30\n",
      "54947/54947 [==============================] - 12s 213us/step - loss: 0.1015 - acc: 0.9522 - val_loss: 3.5594 - val_acc: 0.5860\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.60833\n",
      "Epoch 30/30\n",
      "54947/54947 [==============================] - 12s 211us/step - loss: 0.0962 - acc: 0.9548 - val_loss: 3.5704 - val_acc: 0.5873\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.60833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f67b7a2ff98>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"argmining19_simple-nn-model_cross.hdf5\", monitor='val_acc', \n",
    "                             verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "model.fit([train_args1, train_args2], train_output, batch_size=32, epochs=30, \n",
    "          validation_data=([dev_args1, dev_args2], dev_output), verbose=True,\n",
    "          callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"argmining19_simple-nn-model_cross.hdf5\")\n",
    "dev_output_pred = np.round(model.predict([dev_args1, dev_args2]))\n",
    "test_output_pred = np.round(model.predict([test_args1, test_args2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 718  565]\n",
      " [ 610 1107]]\n",
      "\n",
      "Accuracy:  0.61\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.56      0.55      1283\n",
      "          1       0.66      0.64      0.65      1717\n",
      "\n",
      "avg / total       0.61      0.61      0.61      3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'macro': 0.6, 'micro': 0.61}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev set performance\n",
    "report_training_results(dev_output, dev_output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 935  279]\n",
      " [ 139 1088]]\n",
      "\n",
      "Accuracy:  0.83\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.77      0.82      1214\n",
      "          1       0.80      0.89      0.84      1227\n",
      "\n",
      "avg / total       0.83      0.83      0.83      2441\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'macro': 0.83, 'micro': 0.83}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set performance\n",
    "report_training_results(test_output, test_output_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test set probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_test_all =  pd.read_csv(\"data/same-side-classification/cross-topic/test.csv\", index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/gwiedemann/miniconda3/envs/nnnlp/lib/python3.6/site-packages/bert_serving/client/__init__.py:286: UserWarning: some of your sentences have more tokens than \"max_seq_len=256\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    }
   ],
   "source": [
    "a1 = bc.encode(cross_test_all.argument1.tolist())\n",
    "a2 = bc.encode(cross_test_all.argument2.tolist())\n",
    "testall_embedded_pairs = zip(a1, a2)\n",
    "pickle.dump(testall_embedded_pairs, open(\"BERT_pairs_testall_cross.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6163, 1024)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testall_embs = pickle.load(open(\"BERT_pairs_testall_cross.pkl\",\"rb\"))\n",
    "t1, t2 = zip(*testall_embs)\n",
    "testall_args1 = np.array(t1)\n",
    "testall_args2 = np.array(t2)\n",
    "testall_args1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"argmining19_simple-nn-model_cross.hdf5\")\n",
    "testall_output_pred = model.predict([testall_args1, testall_args2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to disk\n",
    "with open(\"predicted_labels_simple-nn_cross.csv\", \"w\") as f:\n",
    "    for i, a in enumerate(testall_output_pred):\n",
    "        f.write(str(cross_test_all.index.values[i]) + \",\" + str(a[0]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
