{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinct dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_within_path = '../argmining19-same-side-classification/data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4381 pairs\n",
    "* overlapping (both arguments of each test pair have been seen during training)\n",
    "* distinct\n",
    "* random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "data_cross_path = '../argmining19-same-side-classification/data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = '../argmining19-same-side-classification/data/same-side-classification/within-topic/{}.csv'\n",
    "\n",
    "within_train_df = pd.read_csv(data_within_path.format('training'),\n",
    "                                 quotechar='\"',\n",
    "                                 quoting=csv.QUOTE_ALL,\n",
    "                                 encoding='utf-8',\n",
    "                                 escapechar='\\\\',\n",
    "                                 doublequote=False,\n",
    "                                 index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85249</th>\n",
       "      <td>gay marriage devalues marriage, frequency of o...</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>being unaccustomed to gay marriage is no argument</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z</td>\n",
       "      <td>False</td>\n",
       "      <td>gay marriage, debate on same sex marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>accepted. pro may extend their arguments to th...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>i\"m pro-life. just think about it, your murder...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion (pro life)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               argument1  \\\n",
       "id                                                         \n",
       "85249  gay marriage devalues marriage, frequency of o...   \n",
       "2607   accepted. pro may extend their arguments to th...   \n",
       "\n",
       "                                  argument1_id  \\\n",
       "id                                               \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000   \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000   \n",
       "\n",
       "                                               argument2  \\\n",
       "id                                                         \n",
       "85249  being unaccustomed to gay marriage is no argument   \n",
       "2607   i\"m pro-life. just think about it, your murder...   \n",
       "\n",
       "                                  argument2_id                      debate_id  \\\n",
       "id                                                                              \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000  d2f4b1cd-2019-04-17T11:47:27Z   \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000  2a0d32eb-2019-04-18T11:46:44Z   \n",
       "\n",
       "       is_same_side                                      topic  \n",
       "id                                                              \n",
       "85249         False  gay marriage, debate on same sex marriage  \n",
       "2607          False                        abortion (pro life)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abortion should be banned nationally unless it is necessary to save the life of the mother. i added the \"except to save the life of the mother\" part really more to appease those who would say that it should be an exception, though really the only situation that i can think of would be an ectopic pregnancy. to solve that, it does kill the baby, but technically it isn't an abortion, just the removal of a tube. mainly, i want to make it clear that there would be no exceptions for rape/incest, because the issue hear isn't taking responsibility for ones actions; rather it is out of respect for the sanctity of human life.\n",
      "---\n",
      "abortion should be banned nationally unless it is necessary to save the life of the mother. im sorry i was not thinking when i signed this to debate you i toatally agree with you on what you are sayin im just glad there are people out there like you because thats exactly what this country needs.\n"
     ]
    }
   ],
   "source": [
    "print(within_train_df.iloc[3][\"argument1\"])\n",
    "print(\"---\")\n",
    "print(within_train_df.iloc[3][\"argument2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {} # arg_id to cluster_id\n",
    "cluster_total = {} # cluster_id to counts arg_id pairs\n",
    "cluster_unique = {} # cluster_id to set of arg_ids\n",
    "index2cluster = {}\n",
    "cluster2arg = {}\n",
    "both_seen = []\n",
    "delete_candidate = []\n",
    "\n",
    "within_train_df = within_train_df.sort_values(by=['argument1', 'argument2'])\n",
    "\n",
    "def build_index(d):\n",
    "    index = {}\n",
    "    for arg, cluster_id in d.items():\n",
    "        if cluster_id not in index:\n",
    "            index[cluster_id] = set()\n",
    "        index[cluster_id].add(arg)\n",
    "    return index\n",
    "\n",
    "for index, row in within_train_df.iterrows():\n",
    "    \n",
    "    cluster_id = None\n",
    "    \n",
    "    if row['argument1'] in cluster_dict and row['argument2'] in cluster_dict:\n",
    "        both_seen_candidate = True\n",
    "    else:\n",
    "        both_seen_candidate = False\n",
    "    both_seen.append(both_seen_candidate)\n",
    "    \n",
    "    if row['argument1'] in cluster_dict:\n",
    "        cluster_id = cluster_dict[row['argument1']]\n",
    "        if row['argument2'] in cluster_dict and cluster_dict[row['argument1']] != cluster_dict[row['argument2']]:\n",
    "            \n",
    "            # skip some data instances from the original set to receive disconnected partial graphs\n",
    "            delete_candidate.append(True)\n",
    "            continue\n",
    "            \n",
    "            #print('Merge cluster %d to %d' % (cluster_dict[row['argument2']], cluster_dict[row['argument1']]))\n",
    "            #for arg in cluster_unique[cluster_dict[row['argument2']]]:\n",
    "            #    cluster_dict[arg] = cluster_id\n",
    "            #cluster_unique = build_index(cluster_dict)            \n",
    "    elif row['argument2'] in cluster_dict:\n",
    "        cluster_id = cluster_dict[row['argument2']]       \n",
    "    else:\n",
    "        cluster_id = len(cluster_unique)\n",
    "        cluster_unique[cluster_id] = set()\n",
    "        cluster_total[cluster_id] = 0\n",
    "        \n",
    "    cluster_dict[row['argument1']] = cluster_id\n",
    "    cluster_dict[row['argument2']] = cluster_id\n",
    "    \n",
    "    cluster_unique[cluster_id].add(row['argument1'])\n",
    "    cluster_unique[cluster_id].add(row['argument2'])\n",
    "        \n",
    "    cluster_total[cluster_id] += 1\n",
    "    \n",
    "    delete_candidate.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_train_df['del'] = delete_candidate\n",
    "within_train_df['both_seen'] = both_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2cluster = []\n",
    "selected_df = within_train_df[within_train_df['del']==False].copy()\n",
    "for index, row in selected_df.iterrows():\n",
    "    index2cluster.append(cluster_dict[row['argument1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df['cluster'] = index2cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>total</th>\n",
       "      <th>unique</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>21226</td>\n",
       "      <td>251</td>\n",
       "      <td>84.565737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>11678</td>\n",
       "      <td>186</td>\n",
       "      <td>62.784946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>953</td>\n",
       "      <td>3417</td>\n",
       "      <td>100</td>\n",
       "      <td>34.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>1419</td>\n",
       "      <td>66</td>\n",
       "      <td>21.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>540</td>\n",
       "      <td>1271</td>\n",
       "      <td>62</td>\n",
       "      <td>20.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>2027</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>2428</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2429 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cluster_id  total  unique      ratio\n",
       "35            35  21226     251  84.565737\n",
       "147          147  11678     186  62.784946\n",
       "953          953   3417     100  34.170000\n",
       "128          128   1419      66  21.500000\n",
       "540          540   1271      62  20.500000\n",
       "...          ...    ...     ...        ...\n",
       "2027        2027      1       2   0.500000\n",
       "2026        2026      1       2   0.500000\n",
       "2021        2021      1       2   0.500000\n",
       "2016        2016      1       2   0.500000\n",
       "2428        2428      1       2   0.500000\n",
       "\n",
       "[2429 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "for cluster_id in cluster_total.keys():\n",
    "    df_list.append({\n",
    "        'cluster_id' : cluster_id,\n",
    "        'total' : cluster_total[cluster_id],\n",
    "        'unique' : len(cluster_unique[cluster_id]),\n",
    "        'ratio' : cluster_total[cluster_id] / len(cluster_unique[cluster_id])\n",
    "    })\n",
    "df = pd.DataFrame(df_list).sort_values(by=['total'], ascending = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Anscheinend beginnen viele Cluster immer mit dem gleichen Satz... Ich frage mich, was das für einen Einfluss auf die Sequence Pair classification hat..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_total[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62358.0 6235.8\n"
     ]
    }
   ],
   "source": [
    "print(df.sum(0)[1], df.sum(0)[1] * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[740314.0, 53596.0, 6590.0, 2000.5488701341862]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Die nach Größe sortierten Cluster kann man ab einem bestimmten i aufteilen \n",
    "# in gerade/ungerade cluster id und so die etwa gleich großen distinct/overlap\n",
    "# sets erzeugen\n",
    "i = 749\n",
    "df.iloc[:i, :].sum(0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1103447.0, 4384.0, 3490.0, 942.8071428571402]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[i::2, :].sum(0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1105045.0, 4378.0, 3494.0, 939.9499999999971]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[i+1::2, :].sum(0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split distinct datasets\n",
    "train_df = pd.concat([df.iloc[:i, :], df.iloc[i::2, :]])\n",
    "test_df = df.iloc[i+1::2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1843761.0, 57980.0, 10080.0, 2943.3560129913135]\n",
      "[1105045.0, 4378.0, 3494.0, 939.9499999999971]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.sum(0).tolist())\n",
    "print(test_df.sum(0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_train_df = selected_df[selected_df['cluster'].isin(train_df['cluster_id'])]\n",
    "distinct_dev_df = selected_df[selected_df['cluster'].isin(test_df['cluster_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split sets into argument pairs with complete overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_cluster = None\n",
    "both_seen_selection = []\n",
    "selected_args = set()\n",
    "for index, row in selected_df.iterrows():\n",
    "    if row['both_seen']:        \n",
    "        if not (row['argument1'] in selected_args or row['argument2'] in selected_args):\n",
    "            both_seen_selection.append(True)\n",
    "            selected_args.add(row['argument1'])\n",
    "            selected_args.add(row['argument2'])\n",
    "        else:\n",
    "            both_seen_selection.append(False)\n",
    "    else:\n",
    "        both_seen_selection.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4381"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_df['overlap'] = both_seen_selection\n",
    "sum(both_seen_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_train_df = selected_df[selected_df['overlap'] == False]\n",
    "overlap_dev_df = selected_df[selected_df['overlap'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, dev, both, one, distinct: 57977 4381 4274 95 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "rnd_within = shuffle(within_train_df, random_state=17)\n",
    "rnd_dev_df = rnd_within[:4381]\n",
    "rnd_train_df = rnd_within[4381:selected_df.shape[0]]\n",
    "check_splits(rnd_train_df, rnd_dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinct_train_df = shuffle(distinct_train_df)\n",
    "# distinct_test_df = shuffle(distinct_test_df)\n",
    "# overlap_train_df = shuffle(overlap_train_df)\n",
    "# overlap_dev_df = shuffle(overlap_dev_df)\n",
    "\n",
    "with open(\"data/distinct_sets/within-v2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(distinct_train_df, f)\n",
    "    pickle.dump(distinct_dev_df, f)\n",
    "    pickle.dump(overlap_train_df, f)\n",
    "    pickle.dump(overlap_dev_df, f)\n",
    "    pickle.dump(rnd_train_df, f)\n",
    "    pickle.dump(rnd_dev_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33380\n",
      "(62358, 11)\n"
     ]
    }
   ],
   "source": [
    "print(selected_df['is_same_side'].sum())\n",
    "print(selected_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33380\n",
      "(57980, 10)\n"
     ]
    }
   ],
   "source": [
    "print(distinct_train_df['is_same_side'].sum() + distinct_dev_df['is_same_side'].sum())\n",
    "print(distinct_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33380\n",
      "(57977, 11)\n"
     ]
    }
   ],
   "source": [
    "print(overlap_train_df['is_same_side'].sum() + overlap_dev_df['is_same_side'].sum())\n",
    "print(overlap_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33276\n",
      "(57977, 9)\n"
     ]
    }
   ],
   "source": [
    "print(rnd_train_df['is_same_side'].sum() + rnd_dev_df['is_same_side'].sum())\n",
    "print(rnd_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_splits(train, dev):\n",
    "    all_args = set()\n",
    "    for index, row in train.iterrows():\n",
    "        all_args.add(row['argument1'])\n",
    "        all_args.add(row['argument2'])\n",
    "    both = 0\n",
    "    one = 0\n",
    "    distinct = 0\n",
    "    for index, row in dev.iterrows():\n",
    "        if row['argument1'] in all_args and row['argument2'] in all_args:\n",
    "            both +=1\n",
    "        elif row['argument1'] in all_args or row['argument2'] in all_args:\n",
    "            one += 1\n",
    "        else:\n",
    "            distinct += 1\n",
    "    print(\"Train, dev, both, one, distinct:\", train.shape[0], dev.shape[0], both, one, distinct)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, dev, both, one, distinct: 57977 4381 4274 95 12\n"
     ]
    }
   ],
   "source": [
    "check_splits(rnd_train_df, rnd_dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, dev, both, one, distinct: 57977 4381 4381 0 0\n"
     ]
    }
   ],
   "source": [
    "check_splits(overlap_train_df, overlap_dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, dev, both, one, distinct: 57980 4378 0 0 4378\n"
     ]
    }
   ],
   "source": [
    "check_splits(distinct_train_df, distinct_dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check saved dataset\n",
    "import pickle\n",
    "with open(\"data/distinct_sets/within-v2.pkl\", \"rb\") as f:\n",
    "    distinct_train_df = pickle.load(f)\n",
    "    distinct_dev_df = pickle.load(f)\n",
    "    overlap_train_df = pickle.load(f)\n",
    "    overlap_dev_df = pickle.load(f)\n",
    "    rnd_train_df = pickle.load(f)\n",
    "    rnd_dev_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for overlap fo train and dev / duplicates in train etc.\n",
    "# ... apparently there are some duplicates in the original dataset, and some arg1-arg2 arg2-arg1 permutations\n",
    "pair2index = {}\n",
    "for index, row in within_train_df.iterrows():\n",
    "    if row['argument1'] == row['argument2']:\n",
    "        print(index)\n",
    "    comb = row['argument1'] + row['argument2']\n",
    "    if comb in pair2index:\n",
    "        print(\"match\")\n",
    "    if row['argument2'] + row['argument1'] in pair2index:\n",
    "        print(\"march rev\")\n",
    "    pair2index[comb] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# hewever, these duplicates are only few\n",
    "n = 0\n",
    "for index, row in rnd_dev_df.iterrows():\n",
    "    comb = row['argument1'] + row['argument1']\n",
    "    if comb in pair2index:\n",
    "        n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
