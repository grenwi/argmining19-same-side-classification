{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cross_path = '../argmining19-same-side-classification/data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = '../argmining19-same-side-classification/data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score, f1_score\n",
    "def report_training_results(y_test, y_pred):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))  \n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2))  #\n",
    "    print()\n",
    "\n",
    "    print('Report:')\n",
    "    print(classification_report(y_test, y_pred))  \n",
    "    f1_dic = {}\n",
    "    \n",
    "    f1_dic['macro'] = round(f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../argmining19-same-side-classification/data/same-side-classification/cross-topic/training.csv\n",
      "../argmining19-same-side-classification/data/same-side-classification/cross-topic/test.csv\n",
      "../argmining19-same-side-classification/data/same-side-classification/within-topic/training.csv\n",
      "../argmining19-same-side-classification/data/same-side-classification/within-topic/test.csv\n"
     ]
    }
   ],
   "source": [
    "print(data_cross_path.format('training'))\n",
    "cross_train_df = pd.read_csv(data_cross_path.format('training'),\n",
    "                                quotechar='\"',\n",
    "                                quoting=csv.QUOTE_ALL,\n",
    "                                encoding='utf-8',\n",
    "                                escapechar='\\\\',\n",
    "                                doublequote=False,\n",
    "                                index_col='id')\n",
    "print(data_cross_path.format('test'))\n",
    "cross_test_df = pd.read_csv(data_cross_path.format('test'),\n",
    "                            # quotechar='\"',\n",
    "                            # quoting=csv.QUOTE_ALL,\n",
    "                            # encoding='utf-8',\n",
    "                            # escapechar='\\\\',\n",
    "                            # doublequote=False,\n",
    "                            index_col='id')\n",
    "\n",
    "print(data_within_path.format('training'))\n",
    "within_train_df = pd.read_csv(data_within_path.format('training'),\n",
    "                                 quotechar='\"',\n",
    "                                 quoting=csv.QUOTE_ALL,\n",
    "                                 encoding='utf-8',\n",
    "                                 escapechar='\\\\',\n",
    "                                 doublequote=False,\n",
    "                                 index_col='id')\n",
    "print(data_within_path.format('test'))\n",
    "within_test_df = pd.read_csv(data_within_path.format('test'),\n",
    "                             quotechar='\"',\n",
    "                             # quoting=csv.QUOTE_ALL,\n",
    "                             # encoding='utf-8',\n",
    "                             # escapechar='\\\\',\n",
    "                             # doublequote=False,\n",
    "                             index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61048"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cross_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"sorted_data.pkl\", \"rb\") as f:               # argument1_sorted and argument2_sorted columns dec\n",
    "# with open(\"sorted_asc_data.pkl\", \"rb\") as f:           # argument1_sorted and argument2_sorted columns asc\n",
    "# with open(\"summarized_data.pkl\", \"rb\") as f:                  # text rank summarized\n",
    "#     within_train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "    def add_tag(row):\n",
    "        title = row['topic'].lower().strip()\n",
    "        if title.find('abortion') > -1 :\n",
    "            row['tag'] = 'abortion'\n",
    "        elif title.find('gay marriage') > -1 :\n",
    "            row['tag'] = 'gay marriage'\n",
    "        else:\n",
    "            row['tag'] = 'NA'\n",
    "        return row\n",
    "\n",
    "    cross_train_df = cross_train_df.apply(add_tag, axis=1)\n",
    "    # cross_dev_df = cross_dev_df.apply(add_tag, axis=1)\n",
    "    cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "    within_train_df = within_train_df.apply(add_tag, axis=1)\n",
    "    # within_dev_df = within_dev_df.apply(add_tag, axis=1)\n",
    "    within_test_df = within_test_df.apply(add_tag, axis=1)\n",
    "    \n",
    "    with open(\"tagged_data.pkl\", \"wb\") as f:\n",
    "        pickle.dump(cross_train_df, f)\n",
    "        pickle.dump(cross_test_df, f)\n",
    "        pickle.dump(within_train_df, f)\n",
    "        pickle.dump(within_test_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tagged_data.pkl\", \"rb\") as f:\n",
    "    cross_train_df = pickle.load(f)\n",
    "    cross_test_df = pickle.load(f)\n",
    "    within_train_df = pickle.load(f)\n",
    "    within_test_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61028</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00005-000</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00005-000</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z</td>\n",
       "      <td>False</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61029</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00006-000</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00006-000</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z</td>\n",
       "      <td>False</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61030</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00006-000</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00006-000</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z</td>\n",
       "      <td>False</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61031</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00006-000</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00006-000</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z</td>\n",
       "      <td>False</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61032</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00007-000</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00007-000</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z</td>\n",
       "      <td>False</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61033</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00007-000</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00007-000</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z</td>\n",
       "      <td>False</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61034</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00000-000</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00000-000</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z</td>\n",
       "      <td>False</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61035</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00000-000</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00000-000</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z</td>\n",
       "      <td>False</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61036</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00001-000</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00001-000</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z</td>\n",
       "      <td>False</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61037</th>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00002-000</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z-00002-000</td>\n",
       "      <td>ff883bce-2019-04-18T13:50:37Z</td>\n",
       "      <td>False</td>\n",
       "      <td>(resolved)on balance:middleclassandrichwomenwh...</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61038</th>\n",
       "      <td>every human being has rights, even if they can...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00000-000</td>\n",
       "      <td>my opponent states, \"until a baby is born natu...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00000-000</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z</td>\n",
       "      <td>True</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61039</th>\n",
       "      <td>every human being has rights, even if they can...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00000-000</td>\n",
       "      <td>first, i must say that i do not under any circ...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00000-000</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z</td>\n",
       "      <td>True</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61040</th>\n",
       "      <td>yes, but the baby is still not alive, it is st...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00001-000</td>\n",
       "      <td>until a baby is born naturally, it is not trul...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00001-000</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z</td>\n",
       "      <td>True</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61041</th>\n",
       "      <td>my opponent states, \"until a baby is born natu...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00002-000</td>\n",
       "      <td>first, i must say that i do not under any circ...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00002-000</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z</td>\n",
       "      <td>True</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61042</th>\n",
       "      <td>every human being has rights, even if they can...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00000-000</td>\n",
       "      <td>yes, but the baby is still not alive, it is st...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00000-000</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z</td>\n",
       "      <td>False</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61043</th>\n",
       "      <td>every human being has rights, even if they can...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00000-000</td>\n",
       "      <td>until a baby is born naturally, it is not trul...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00000-000</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z</td>\n",
       "      <td>False</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61044</th>\n",
       "      <td>yes, but the baby is still not alive, it is st...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00001-000</td>\n",
       "      <td>my opponent states, \"until a baby is born natu...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00001-000</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z</td>\n",
       "      <td>False</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61045</th>\n",
       "      <td>yes, but the baby is still not alive, it is st...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00001-000</td>\n",
       "      <td>first, i must say that i do not under any circ...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00001-000</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z</td>\n",
       "      <td>False</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61046</th>\n",
       "      <td>my opponent states, \"until a baby is born natu...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00002-000</td>\n",
       "      <td>until a baby is born naturally, it is not trul...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00002-000</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z</td>\n",
       "      <td>False</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61047</th>\n",
       "      <td>until a baby is born naturally, it is not trul...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00003-000</td>\n",
       "      <td>first, i must say that i do not under any circ...</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z-00003-000</td>\n",
       "      <td>ffec9266-2019-04-18T19:30:12Z</td>\n",
       "      <td>False</td>\n",
       "      <td>live birth abortion should stay illegal.</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               argument1  \\\n",
       "id                                                         \n",
       "61028  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61029  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61030  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61031  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61032  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61033  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61034  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61035  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61036  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61037  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61038  every human being has rights, even if they can...   \n",
       "61039  every human being has rights, even if they can...   \n",
       "61040  yes, but the baby is still not alive, it is st...   \n",
       "61041  my opponent states, \"until a baby is born natu...   \n",
       "61042  every human being has rights, even if they can...   \n",
       "61043  every human being has rights, even if they can...   \n",
       "61044  yes, but the baby is still not alive, it is st...   \n",
       "61045  yes, but the baby is still not alive, it is st...   \n",
       "61046  my opponent states, \"until a baby is born natu...   \n",
       "61047  until a baby is born naturally, it is not trul...   \n",
       "\n",
       "                                  argument1_id  \\\n",
       "id                                               \n",
       "61028  ff883bce-2019-04-18T13:50:37Z-00005-000   \n",
       "61029  ff883bce-2019-04-18T13:50:37Z-00006-000   \n",
       "61030  ff883bce-2019-04-18T13:50:37Z-00006-000   \n",
       "61031  ff883bce-2019-04-18T13:50:37Z-00006-000   \n",
       "61032  ff883bce-2019-04-18T13:50:37Z-00007-000   \n",
       "61033  ff883bce-2019-04-18T13:50:37Z-00007-000   \n",
       "61034  ff883bce-2019-04-18T13:50:37Z-00000-000   \n",
       "61035  ff883bce-2019-04-18T13:50:37Z-00000-000   \n",
       "61036  ff883bce-2019-04-18T13:50:37Z-00001-000   \n",
       "61037  ff883bce-2019-04-18T13:50:37Z-00002-000   \n",
       "61038  ffec9266-2019-04-18T19:30:12Z-00000-000   \n",
       "61039  ffec9266-2019-04-18T19:30:12Z-00000-000   \n",
       "61040  ffec9266-2019-04-18T19:30:12Z-00001-000   \n",
       "61041  ffec9266-2019-04-18T19:30:12Z-00002-000   \n",
       "61042  ffec9266-2019-04-18T19:30:12Z-00000-000   \n",
       "61043  ffec9266-2019-04-18T19:30:12Z-00000-000   \n",
       "61044  ffec9266-2019-04-18T19:30:12Z-00001-000   \n",
       "61045  ffec9266-2019-04-18T19:30:12Z-00001-000   \n",
       "61046  ffec9266-2019-04-18T19:30:12Z-00002-000   \n",
       "61047  ffec9266-2019-04-18T19:30:12Z-00003-000   \n",
       "\n",
       "                                               argument2  \\\n",
       "id                                                         \n",
       "61028  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61029  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61030  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61031  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61032  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61033  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61034  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61035  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61036  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61037  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61038  my opponent states, \"until a baby is born natu...   \n",
       "61039  first, i must say that i do not under any circ...   \n",
       "61040  until a baby is born naturally, it is not trul...   \n",
       "61041  first, i must say that i do not under any circ...   \n",
       "61042  yes, but the baby is still not alive, it is st...   \n",
       "61043  until a baby is born naturally, it is not trul...   \n",
       "61044  my opponent states, \"until a baby is born natu...   \n",
       "61045  first, i must say that i do not under any circ...   \n",
       "61046  until a baby is born naturally, it is not trul...   \n",
       "61047  first, i must say that i do not under any circ...   \n",
       "\n",
       "                                  argument2_id                      debate_id  \\\n",
       "id                                                                              \n",
       "61028  ff883bce-2019-04-18T13:50:37Z-00005-000  ff883bce-2019-04-18T13:50:37Z   \n",
       "61029  ff883bce-2019-04-18T13:50:37Z-00006-000  ff883bce-2019-04-18T13:50:37Z   \n",
       "61030  ff883bce-2019-04-18T13:50:37Z-00006-000  ff883bce-2019-04-18T13:50:37Z   \n",
       "61031  ff883bce-2019-04-18T13:50:37Z-00006-000  ff883bce-2019-04-18T13:50:37Z   \n",
       "61032  ff883bce-2019-04-18T13:50:37Z-00007-000  ff883bce-2019-04-18T13:50:37Z   \n",
       "61033  ff883bce-2019-04-18T13:50:37Z-00007-000  ff883bce-2019-04-18T13:50:37Z   \n",
       "61034  ff883bce-2019-04-18T13:50:37Z-00000-000  ff883bce-2019-04-18T13:50:37Z   \n",
       "61035  ff883bce-2019-04-18T13:50:37Z-00000-000  ff883bce-2019-04-18T13:50:37Z   \n",
       "61036  ff883bce-2019-04-18T13:50:37Z-00001-000  ff883bce-2019-04-18T13:50:37Z   \n",
       "61037  ff883bce-2019-04-18T13:50:37Z-00002-000  ff883bce-2019-04-18T13:50:37Z   \n",
       "61038  ffec9266-2019-04-18T19:30:12Z-00000-000  ffec9266-2019-04-18T19:30:12Z   \n",
       "61039  ffec9266-2019-04-18T19:30:12Z-00000-000  ffec9266-2019-04-18T19:30:12Z   \n",
       "61040  ffec9266-2019-04-18T19:30:12Z-00001-000  ffec9266-2019-04-18T19:30:12Z   \n",
       "61041  ffec9266-2019-04-18T19:30:12Z-00002-000  ffec9266-2019-04-18T19:30:12Z   \n",
       "61042  ffec9266-2019-04-18T19:30:12Z-00000-000  ffec9266-2019-04-18T19:30:12Z   \n",
       "61043  ffec9266-2019-04-18T19:30:12Z-00000-000  ffec9266-2019-04-18T19:30:12Z   \n",
       "61044  ffec9266-2019-04-18T19:30:12Z-00001-000  ffec9266-2019-04-18T19:30:12Z   \n",
       "61045  ffec9266-2019-04-18T19:30:12Z-00001-000  ffec9266-2019-04-18T19:30:12Z   \n",
       "61046  ffec9266-2019-04-18T19:30:12Z-00002-000  ffec9266-2019-04-18T19:30:12Z   \n",
       "61047  ffec9266-2019-04-18T19:30:12Z-00003-000  ffec9266-2019-04-18T19:30:12Z   \n",
       "\n",
       "       is_same_side                                              topic  \\\n",
       "id                                                                       \n",
       "61028         False  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61029         False  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61030         False  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61031         False  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61032         False  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61033         False  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61034         False  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61035         False  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61036         False  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61037         False  (resolved)on balance:middleclassandrichwomenwh...   \n",
       "61038          True           live birth abortion should stay illegal.   \n",
       "61039          True           live birth abortion should stay illegal.   \n",
       "61040          True           live birth abortion should stay illegal.   \n",
       "61041          True           live birth abortion should stay illegal.   \n",
       "61042         False           live birth abortion should stay illegal.   \n",
       "61043         False           live birth abortion should stay illegal.   \n",
       "61044         False           live birth abortion should stay illegal.   \n",
       "61045         False           live birth abortion should stay illegal.   \n",
       "61046         False           live birth abortion should stay illegal.   \n",
       "61047         False           live birth abortion should stay illegal.   \n",
       "\n",
       "            tag  \n",
       "id               \n",
       "61028  abortion  \n",
       "61029  abortion  \n",
       "61030  abortion  \n",
       "61031  abortion  \n",
       "61032  abortion  \n",
       "61033  abortion  \n",
       "61034  abortion  \n",
       "61035  abortion  \n",
       "61036  abortion  \n",
       "61037  abortion  \n",
       "61038  abortion  \n",
       "61039  abortion  \n",
       "61040  abortion  \n",
       "61041  abortion  \n",
       "61042  abortion  \n",
       "61043  abortion  \n",
       "61044  abortion  \n",
       "61045  abortion  \n",
       "61046  abortion  \n",
       "61047  abortion  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_train_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i would like to start off by thanking my oppon...</td>\n",
       "      <td>i was hoping that since this member took the t...</td>\n",
       "      <td>gay marriage is wrong</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i would like to start off by thanking my oppon...</td>\n",
       "      <td>hello, i am new to this website and usually de...</td>\n",
       "      <td>gay marriage is wrong</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            argument1  \\\n",
       "id                                                      \n",
       "0   i would like to start off by thanking my oppon...   \n",
       "1   i would like to start off by thanking my oppon...   \n",
       "\n",
       "                                            argument2                  topic  \\\n",
       "id                                                                             \n",
       "0   i was hoping that since this member took the t...  gay marriage is wrong   \n",
       "1   hello, i am new to this website and usually de...  gay marriage is wrong   \n",
       "\n",
       "             tag  \n",
       "id                \n",
       "0   gay marriage  \n",
       "1   gay marriage  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85249</th>\n",
       "      <td>gay marriage devalues marriage, frequency of o...</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>being unaccustomed to gay marriage is no argument</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z-00063-000</td>\n",
       "      <td>d2f4b1cd-2019-04-17T11:47:27Z</td>\n",
       "      <td>False</td>\n",
       "      <td>gay marriage, debate on same sex marriage</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>accepted. pro may extend their arguments to th...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>i\"m pro-life. just think about it, your murder...</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z-00004-000</td>\n",
       "      <td>2a0d32eb-2019-04-18T11:46:44Z</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion (pro life)</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               argument1  \\\n",
       "id                                                         \n",
       "85249  gay marriage devalues marriage, frequency of o...   \n",
       "2607   accepted. pro may extend their arguments to th...   \n",
       "\n",
       "                                  argument1_id  \\\n",
       "id                                               \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000   \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000   \n",
       "\n",
       "                                               argument2  \\\n",
       "id                                                         \n",
       "85249  being unaccustomed to gay marriage is no argument   \n",
       "2607   i\"m pro-life. just think about it, your murder...   \n",
       "\n",
       "                                  argument2_id                      debate_id  \\\n",
       "id                                                                              \n",
       "85249  d2f4b1cd-2019-04-17T11:47:27Z-00063-000  d2f4b1cd-2019-04-17T11:47:27Z   \n",
       "2607   2a0d32eb-2019-04-18T11:46:44Z-00004-000  2a0d32eb-2019-04-18T11:46:44Z   \n",
       "\n",
       "       is_same_side                                      topic           tag  \n",
       "id                                                                            \n",
       "85249         False  gay marriage, debate on same sex marriage  gay marriage  \n",
       "2607          False                        abortion (pro life)      abortion  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i would like to start off by thanking my oppon...</td>\n",
       "      <td>hello, i am new to this website and usually de...</td>\n",
       "      <td>gay marriage is wrong</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>don't judge a book by its cover. you neef obje...</td>\n",
       "      <td>the bible has multiple versions so you can't s...</td>\n",
       "      <td>gay marriage is wrong</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            argument1  \\\n",
       "id                                                      \n",
       "11  i would like to start off by thanking my oppon...   \n",
       "20  don't judge a book by its cover. you neef obje...   \n",
       "\n",
       "                                            argument2                  topic  \\\n",
       "id                                                                             \n",
       "11  hello, i am new to this website and usually de...  gay marriage is wrong   \n",
       "20  the bible has multiple versions so you can't s...  gay marriage is wrong   \n",
       "\n",
       "             tag  \n",
       "id                \n",
       "11  gay marriage  \n",
       "20  gay marriage  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split for final paper experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51760\n",
      "5752\n",
      "6391\n"
     ]
    }
   ],
   "source": [
    "within_tmp, within_test = train_test_split(within_train_df, test_size=0.1, random_state=9721, shuffle=True)\n",
    "within_train, within_dev = train_test_split(within_tmp, test_size=0.1, random_state=9721, shuffle=True)\n",
    "print(len(within_train))\n",
    "print(len(within_dev))\n",
    "print(len(within_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54943\n",
      "6105\n",
      "18724\n"
     ]
    }
   ],
   "source": [
    "cross_train, cross_dev = train_test_split(cross_train_df, test_size=0.1, random_state=9721, shuffle=True)\n",
    "cross_test = within_train[within_train.tag == \"gay marriage\"]\n",
    "print(len(cross_train))\n",
    "print(len(cross_dev))\n",
    "print(len(cross_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"acl2020_data_split.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cross_train, f)\n",
    "    pickle.dump(cross_dev, f)\n",
    "    pickle.dump(cross_test, f)\n",
    "    pickle.dump(within_train, f)\n",
    "    pickle.dump(within_dev, f)\n",
    "    pickle.dump(within_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"acl2020_data_split.pkl\", \"rb\") as f:\n",
    "    cross_train = pickle.load(f)\n",
    "    cross_dev = pickle.load(f)\n",
    "    cross_test = pickle.load(f)    \n",
    "    within_train = pickle.load(f)\n",
    "    within_dev = pickle.load(f)\n",
    "    within_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def get_reversed_examples(dataset):\n",
    "    reversed_set = []\n",
    "    for t in dataset:\n",
    "        reversed_set.append((t[1], t[0], t[2]))\n",
    "    return reversed_set\n",
    "        \n",
    "\n",
    "def get_train_test_sets(df, ratio=0.30, random_state=1, reverse_trainset = False):\n",
    "    X = df[['argument1', 'argument2', 'argument1_id', 'argument2_id', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=ratio,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "    trainset = list(zip(X_train.argument1.tolist(), X_train.argument2.tolist(), y_train.is_same_side.tolist()))\n",
    "    testset = list(zip(X_test.argument1.tolist(), X_test.argument2.tolist(), y_test.is_same_side.tolist()))\n",
    "    \n",
    "    if reverse_trainset:\n",
    "        trainset = trainset + get_reversed_examples(trainset)\n",
    "        \n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev = get_train_test_sets(within_train_df, reverse_trainset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train[:10000]\n",
    "# X_dev = X_dev[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomization experiments: \n",
    "# Exp 1: we shuffle the order of sentences in the dev set\n",
    "# Exp 2: we shuffle the order of sentences in the training set\n",
    "\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# from random import shuffle\n",
    "\n",
    "# def shuffle_sentences(text):\n",
    "#     s = sent_tokenize(text)\n",
    "#     shuffle(s)\n",
    "#     return \" \".join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_dev_rnd = []\n",
    "# for item in X_dev:\n",
    "#     X_dev_rnd.append((shuffle_sentences(item[0]), shuffle_sentences(item[1]), item[2]))\n",
    "# X_dev = X_dev_rnd\n",
    "\n",
    "# X_train_rnd = []\n",
    "# for item in X_train:\n",
    "#     X_train_rnd.append((shuffle_sentences(item[0]), shuffle_sentences(item[1]), item[2]))\n",
    "# X_train = X_train_rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Within topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "import random\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from transformers import (WEIGHTS_NAME, BertConfig, BertTokenizer,\n",
    "                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n",
    "                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
    "                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
    "\n",
    "from transformers import AdamW, WarmupLinearSchedule\n",
    "\n",
    "from utils import (convert_examples_to_features, output_modes, processors, BertForBinaryClassification)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data_dir': 'data/',\n",
    "    'model_type':  'bert',\n",
    "    'model_name': 'bert-base-uncased',\n",
    "    'task_name': 'binary',\n",
    "    'output_dir': 'outputs/',\n",
    "    'cache_dir': 'cache/',\n",
    "    'do_train': True,\n",
    "    'do_eval': True,\n",
    "    'fp16': False,\n",
    "    'fp16_opt_level': 'O1',\n",
    "    'max_seq_length': 512,\n",
    "    'output_mode': 'classification',\n",
    "    'train_batch_size': 2,\n",
    "    'eval_batch_size': 2,\n",
    "\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'num_train_epochs': 3,\n",
    "    'weight_decay': 0,\n",
    "    'learning_rate': 5e-6,\n",
    "    'adam_epsilon': 1e-9,\n",
    "    'warmup_steps': 0,\n",
    "    'max_grad_norm': 1.0,\n",
    "\n",
    "    'logging_steps': 0,\n",
    "    'evaluate_during_training': True,\n",
    "    'save_steps': 8000,\n",
    "    'eval_all_checkpoints': True,\n",
    "    'overwrite_output_dir': False,\n",
    "    'reprocess_input_data': True,\n",
    "    'notes': 'SameSide argument classification task'\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertConfig, BertForBinaryClassification, BertTokenizer),\n",
    "    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
    "    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
    "    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
    "}\n",
    "\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args['model_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /srv/home/gwiedemann/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /srv/home/gwiedemann/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(args['model_name'], num_labels=1, finetuning_task=args['task_name'])\n",
    "tokenizer = tokenizer_class.from_pretrained(args['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /srv/home/gwiedemann/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /srv/home/gwiedemann/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "INFO:transformers.modeling_utils:Weights of BertForBinaryClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForBinaryClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "model = model_class.from_pretrained(args['model_name'], num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForBinaryClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = args['task_name']\n",
    "\n",
    "processor = processors[task](X_train, X_dev)\n",
    "label_list = processor.get_labels()\n",
    "num_labels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(task, tokenizer, evaluate=False):\n",
    "    processor = processors[task](X_train, X_dev)\n",
    "    output_mode = args['output_mode']\n",
    "    \n",
    "    mode = 'dev' if evaluate else 'train'\n",
    "    cached_features_file = os.path.join(args['data_dir'], f\"cached_{mode}_{args['model_name']}_{args['max_seq_length']}_{task}\")\n",
    "    \n",
    "    if os.path.exists(cached_features_file) and not args['reprocess_input_data']:\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "               \n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", args['data_dir'])\n",
    "        label_list = processor.get_labels()\n",
    "        examples = processor.get_dev_examples(args['data_dir']) if evaluate else processor.get_train_examples(args['data_dir'])\n",
    "        \n",
    "        features = convert_examples_to_features(examples, label_list, args['max_seq_length'], tokenizer, output_mode,\n",
    "            cls_token_at_end=bool(args['model_type'] in ['xlnet']),            # xlnet has a cls token at the end\n",
    "            cls_token=tokenizer.cls_token,\n",
    "            sep_token=tokenizer.sep_token,\n",
    "            cls_token_segment_id=2 if args['model_type'] in ['xlnet'] else 0,\n",
    "            pad_on_left=bool(args['model_type'] in ['xlnet']),                 # pad on the left for xlnet\n",
    "            pad_token_segment_id=4 if args['model_type'] in ['xlnet'] else 0)\n",
    "        \n",
    "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "        torch.save(features, cached_features_file)\n",
    "        \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    # labels\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    return dataset\n",
    "\n",
    "                                        \n",
    "from pprint import pprint\n",
    "                                        \n",
    "def train(train_dataset, model, tokenizer):\n",
    "    tb_writer = SummaryWriter()\n",
    "    \n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args['train_batch_size'])\n",
    "    \n",
    "    t_total = len(train_dataloader) // args['gradient_accumulation_steps'] * args['num_train_epochs']\n",
    "    \n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=args['adam_epsilon'])\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args['warmup_steps'], t_total=t_total)\n",
    "    \n",
    "    if args['fp16']:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args['fp16_opt_level'])\n",
    "        \n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args['num_train_epochs'])\n",
    "    logger.info(\"  Total train batch size  = %d\", args['train_batch_size'])\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args['gradient_accumulation_steps'])\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(args['num_train_epochs']), desc=\"Epoch\")\n",
    "    \n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "            print(\"\\r%f\" % loss, end='')\n",
    "\n",
    "            if args['gradient_accumulation_steps'] > 1:\n",
    "                loss = loss / args['gradient_accumulation_steps']\n",
    "\n",
    "            if args['fp16']:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args['max_grad_norm'])\n",
    "                \n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args['max_grad_norm'])\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "\n",
    "                global_step += 1\n",
    "\n",
    "                if args['logging_steps'] > 0 and global_step % args['logging_steps'] == 0:\n",
    "                    # Log metrics\n",
    "                    if args['evaluate_during_training']:  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results, _ = evaluate(model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar('eval_{}'.format(key), value, global_step)\n",
    "                    tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar('loss', (tr_loss - logging_loss)/args['logging_steps'], global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if args['save_steps'] > 0 and global_step % args['save_steps'] == 0:\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(args['output_dir'], 'checkpoint-{}'.format(global_step))\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, matthews_corrcoef, confusion_matrix, accuracy_score, f1_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def get_mismatched(labels, preds):\n",
    "    mismatched = labels != preds\n",
    "    examples = processor.get_dev_examples(args['data_dir'])\n",
    "    wrong = [i for (i, v) in zip(examples, mismatched) if v]\n",
    "    \n",
    "    return wrong\n",
    "\n",
    "def get_eval_report(labels, preds):\n",
    "    \n",
    "    print(labels)\n",
    "    print(preds)\n",
    "    \n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    return {\n",
    "        \"mcc\": mcc,\n",
    "        \"tp\": tp,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"acc\" : acc,\n",
    "        \"f1\" : f1\n",
    "    }, get_mismatched(labels, preds)\n",
    "\n",
    "def compute_metrics(task_name, preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return get_eval_report(labels, preds)\n",
    "\n",
    "def evaluate(model, tokenizer, prefix=\"\"):\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_output_dir = args['output_dir']\n",
    "\n",
    "    results = {}\n",
    "    EVAL_TASK = args['task_name']\n",
    "\n",
    "    eval_dataset = load_and_cache_examples(EVAL_TASK, tokenizer, evaluate=True)\n",
    "    if not os.path.exists(eval_output_dir):\n",
    "        os.makedirs(eval_output_dir)\n",
    "\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    \n",
    "    sigmoid_squash = torch.nn.Sigmoid()\n",
    "    \n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "            \n",
    "            logits = sigmoid_squash(logits)\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        \n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy())\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    if args['output_mode'] == \"classification\":\n",
    "        # preds = np.argmax(preds, axis=1)\n",
    "        preds = np.round(preds).astype(int)\n",
    "    elif args['output_mode'] == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    # print(preds)\n",
    "    result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n",
    "    results.update(result)\n",
    "\n",
    "    output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return results, wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 44732/44732 [00:28<00:00, 1558.13it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_train_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running training *****\n",
      "INFO:__main__:  Num examples = 44732\n",
      "INFO:__main__:  Num Epochs = 3\n",
      "INFO:__main__:  Total train batch size  = 2\n",
      "INFO:__main__:  Gradient Accumulation steps = 1\n",
      "INFO:__main__:  Total optimization steps = 67098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8a73f0c1e0487fa448d54054beb97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c37e5bcd9a4122b850ba275c9943a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=22366, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006424"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-8000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-8000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-40000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-40000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-40000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008518\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf1561cfa8141cb8dd4065bfd677184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=22366, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-48000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-48000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-48000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005615"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-56000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-56000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-56000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-64000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.009944"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-64000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-64000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.170147"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: global_step = 67098, average loss = 0.41880045810907135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args['do_train']:\n",
    "    train_dataset = load_and_cache_examples(task, tokenizer)\n",
    "    global_step, tr_loss = train(train_dataset, model, tokenizer)\n",
    "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saving model checkpoint to outputs/\n",
      "INFO:transformers.configuration_utils:Configuration saved in outputs/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "if args['do_train']:\n",
    "    if not os.path.exists(args['output_dir']):\n",
    "            os.makedirs(args['output_dir'])\n",
    "    logger.info(\"Saving model checkpoint to %s\", args['output_dir'])\n",
    "    \n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "    model_to_save.save_pretrained(args['output_dir'])\n",
    "    tokenizer.save_pretrained(args['output_dir'])\n",
    "    torch.save(args, os.path.join(args['output_dir'], 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluate the following checkpoints: ['outputs/checkpoint-16000', 'outputs/checkpoint-24000', 'outputs/checkpoint-32000', 'outputs/checkpoint-40000', 'outputs/checkpoint-48000', 'outputs/checkpoint-56000', 'outputs/checkpoint-64000', 'outputs/checkpoint-8000', 'outputs']\n",
      "INFO:transformers.configuration_utils:loading configuration file outputs/checkpoint-16000/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file outputs/checkpoint-16000/pytorch_model.bin\n",
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 19171/19171 [00:31<00:00, 612.52it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_dev_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running evaluation 16000 *****\n",
      "INFO:__main__:  Num examples = 19171\n",
      "INFO:__main__:  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e6f11478cf4948b0b972d6c3b7545f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9586, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 16000 *****\n",
      "INFO:__main__:  acc = 0.859057952115174\n",
      "INFO:__main__:  f1 = 0.8612223934257832\n",
      "INFO:__main__:  fn = 1954\n",
      "INFO:__main__:  fp = 748\n",
      "INFO:__main__:  mcc = 0.7248763309343006\n",
      "INFO:__main__:  tn = 8085\n",
      "INFO:__main__:  tp = 8384\n",
      "INFO:transformers.configuration_utils:loading configuration file outputs/checkpoint-24000/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file outputs/checkpoint-24000/pytorch_model.bin\n",
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 19171/19171 [00:30<00:00, 625.52it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_dev_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running evaluation 24000 *****\n",
      "INFO:__main__:  Num examples = 19171\n",
      "INFO:__main__:  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0454904438864636a42616908f8eba02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9586, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 24000 *****\n",
      "INFO:__main__:  acc = 0.8686557821709874\n",
      "INFO:__main__:  f1 = 0.8746390520760728\n",
      "INFO:__main__:  fn = 1554\n",
      "INFO:__main__:  fp = 964\n",
      "INFO:__main__:  mcc = 0.7383652347173861\n",
      "INFO:__main__:  tn = 7869\n",
      "INFO:__main__:  tp = 8784\n",
      "INFO:transformers.configuration_utils:loading configuration file outputs/checkpoint-32000/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file outputs/checkpoint-32000/pytorch_model.bin\n",
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 19171/19171 [00:30<00:00, 633.44it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_dev_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running evaluation 32000 *****\n",
      "INFO:__main__:  Num examples = 19171\n",
      "INFO:__main__:  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af17d60a25614fca91efc7a14eb8c627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9586, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 32000 *****\n",
      "INFO:__main__:  acc = 0.8732982108392885\n",
      "INFO:__main__:  f1 = 0.8775767350435965\n",
      "INFO:__main__:  fn = 1632\n",
      "INFO:__main__:  fp = 797\n",
      "INFO:__main__:  mcc = 0.7496132216880128\n",
      "INFO:__main__:  tn = 8036\n",
      "INFO:__main__:  tp = 8706\n",
      "INFO:transformers.configuration_utils:loading configuration file outputs/checkpoint-40000/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file outputs/checkpoint-40000/pytorch_model.bin\n",
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 19171/19171 [00:30<00:00, 619.82it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_dev_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running evaluation 40000 *****\n",
      "INFO:__main__:  Num examples = 19171\n",
      "INFO:__main__:  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63eceac735ac4adaa681978b6ef829bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9586, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 40000 *****\n",
      "INFO:__main__:  acc = 0.8770538834698242\n",
      "INFO:__main__:  f1 = 0.8841028666961696\n",
      "INFO:__main__:  fn = 1348\n",
      "INFO:__main__:  fp = 1009\n",
      "INFO:__main__:  mcc = 0.7537469528333317\n",
      "INFO:__main__:  tn = 7824\n",
      "INFO:__main__:  tp = 8990\n",
      "INFO:transformers.configuration_utils:loading configuration file outputs/checkpoint-48000/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file outputs/checkpoint-48000/pytorch_model.bin\n",
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 19171/19171 [00:30<00:00, 626.21it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_dev_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running evaluation 48000 *****\n",
      "INFO:__main__:  Num examples = 19171\n",
      "INFO:__main__:  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4431ef1e753b42048de5b813c19a9322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9586, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 48000 *****\n",
      "INFO:__main__:  acc = 0.8825309060560221\n",
      "INFO:__main__:  f1 = 0.8876023158315033\n",
      "INFO:__main__:  fn = 1446\n",
      "INFO:__main__:  fp = 806\n",
      "INFO:__main__:  mcc = 0.7665588398256311\n",
      "INFO:__main__:  tn = 8027\n",
      "INFO:__main__:  tp = 8892\n",
      "INFO:transformers.configuration_utils:loading configuration file outputs/checkpoint-56000/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file outputs/checkpoint-56000/pytorch_model.bin\n",
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 19171/19171 [00:31<00:00, 617.83it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_dev_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running evaluation 56000 *****\n",
      "INFO:__main__:  Num examples = 19171\n",
      "INFO:__main__:  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de90039edeb445fbbf43f4c513054572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9586, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 56000 *****\n",
      "INFO:__main__:  acc = 0.8877471180428773\n",
      "INFO:__main__:  f1 = 0.8936758893280632\n",
      "INFO:__main__:  fn = 1294\n",
      "INFO:__main__:  fp = 858\n",
      "INFO:__main__:  mcc = 0.7757178284473939\n",
      "INFO:__main__:  tn = 7975\n",
      "INFO:__main__:  tp = 9044\n",
      "INFO:transformers.configuration_utils:loading configuration file outputs/checkpoint-64000/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file outputs/checkpoint-64000/pytorch_model.bin\n",
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 19171/19171 [00:30<00:00, 625.56it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_dev_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running evaluation 64000 *****\n",
      "INFO:__main__:  Num examples = 19171\n",
      "INFO:__main__:  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cccf9d5511a4a94bd11f8f1b98b999c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9586, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 64000 *****\n",
      "INFO:__main__:  acc = 0.8884252256011684\n",
      "INFO:__main__:  f1 = 0.8936614466815809\n",
      "INFO:__main__:  fn = 1350\n",
      "INFO:__main__:  fp = 789\n",
      "INFO:__main__:  mcc = 0.7778374167811796\n",
      "INFO:__main__:  tn = 8044\n",
      "INFO:__main__:  tp = 8988\n",
      "INFO:transformers.configuration_utils:loading configuration file outputs/checkpoint-8000/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file outputs/checkpoint-8000/pytorch_model.bin\n",
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 19171/19171 [00:29<00:00, 639.09it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_dev_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running evaluation 8000 *****\n",
      "INFO:__main__:  Num examples = 19171\n",
      "INFO:__main__:  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69a1bc425e14bf58e847968db834d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9586, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 8000 *****\n",
      "INFO:__main__:  acc = 0.8345417557769548\n",
      "INFO:__main__:  f1 = 0.8314558979808714\n",
      "INFO:__main__:  fn = 2514\n",
      "INFO:__main__:  fp = 658\n",
      "INFO:__main__:  mcc = 0.6847731222311811\n",
      "INFO:__main__:  tn = 8175\n",
      "INFO:__main__:  tp = 7824\n",
      "INFO:transformers.configuration_utils:loading configuration file outputs/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file outputs/pytorch_model.bin\n",
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 19171/19171 [00:31<00:00, 613.41it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_dev_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running evaluation outputs *****\n",
      "INFO:__main__:  Num examples = 19171\n",
      "INFO:__main__:  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd4c16c59da46ad8a2c07ac089e8ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=9586, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results outputs *****\n",
      "INFO:__main__:  acc = 0.8885817119607741\n",
      "INFO:__main__:  f1 = 0.8939845145920191\n",
      "INFO:__main__:  fn = 1332\n",
      "INFO:__main__:  fp = 804\n",
      "INFO:__main__:  mcc = 0.7779384055882357\n",
      "INFO:__main__:  tn = 8029\n",
      "INFO:__main__:  tp = 9006\n"
     ]
    }
   ],
   "source": [
    "if args['do_eval']:\n",
    "    results = {}\n",
    "    checkpoints = [args['output_dir']]\n",
    "    if args['eval_all_checkpoints']:\n",
    "        checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args['output_dir'] + '/**/' + WEIGHTS_NAME, recursive=True)))\n",
    "        logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "    for checkpoint in checkpoints:\n",
    "        global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n",
    "        model = model_class.from_pretrained(checkpoint)\n",
    "        model.to(device)\n",
    "        result, wrong_preds = evaluate(model, tokenizer, prefix=global_step)\n",
    "        result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())\n",
    "        results.update(result)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Exp 1: shuffling of sentences in dev set does not drop performance!\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.830212299827865\n",
    "INFO:__main__:  f1 = 0.835978835978836\n",
    "INFO:__main__:  fn = 2043\n",
    "INFO:__main__:  fp = 1212\n",
    "INFO:__main__:  mcc = 0.6631362449070034\n",
    "INFO:__main__:  tn = 7621\n",
    "INFO:__main__:  tp = 8295\n",
    "\n",
    "# Exp 2: shuffling of sentences during training seems to be beneficial \n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.8345939178968234\n",
    "INFO:__main__:  f1 = 0.8448706031994521\n",
    "INFO:__main__:  fn = 1703\n",
    "INFO:__main__:  fp = 1468\n",
    "INFO:__main__:  mcc = 0.6679822876284466\n",
    "INFO:__main__:  tn = 7365\n",
    "INFO:__main__:  tp = 8635\n",
    "\n",
    "\n",
    "# Exp 3: UKPSAM argumentative score highest (seems to harm)\n",
    "INFO:__main__:***** Eval results 4000 *****\n",
    "INFO:__main__:  acc = 0.8274998695947003\n",
    "INFO:__main__:  f1 = 0.8363924207193391\n",
    "INFO:__main__:  fn = 1885\n",
    "INFO:__main__:  fp = 1422\n",
    "INFO:__main__:  mcc = 0.6549479251011726\n",
    "INFO:__main__:  tn = 7411\n",
    "INFO:__main__:  tp = 8453\n",
    "\n",
    "# Exp 4: UKPSAM argumentative score lowest (seems to improve)\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.843930937353294\n",
    "INFO:__main__:  f1 = 0.8506240639041438\n",
    "INFO:__main__:  fn = 1819\n",
    "INFO:__main__:  fp = 1173\n",
    "INFO:__main__:  mcc = 0.6891589426394182\n",
    "INFO:__main__:  tn = 7660\n",
    "INFO:__main__:  tp = 8519\n",
    "\n",
    "# Exp 5: relevance score testrank summarization\n",
    "INFO:__main__:***** Eval results 3000 *****\n",
    "INFO:__main__:  acc = 0.8342287830577435\n",
    "INFO:__main__:  f1 = 0.841622645270607\n",
    "INFO:__main__:  fn = 1894\n",
    "INFO:__main__:  fp = 1284\n",
    "INFO:__main__:  mcc = 0.6694302549711013\n",
    "INFO:__main__:  tn = 7549\n",
    "INFO:__main__:  tp = 8444"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INFO:__main__:***** Eval results 4000 *****\n",
    "INFO:__main__:  acc = 0.8328725679411612\n",
    "INFO:__main__:  f1 = 0.8391404759514008\n",
    "INFO:__main__:  fn = 1981\n",
    "INFO:__main__:  fp = 1223\n",
    "INFO:__main__:  mcc = 0.6678514131736567\n",
    "INFO:__main__:  tn = 7610\n",
    "INFO:__main__:  tp = 8357\n",
    "        \n",
    "        \n",
    "# sigmoid, with extra linear layer\n",
    "INFO:__main__:***** Eval results 4000 *****\n",
    "INFO:__main__:  acc = 0.8386625632465703\n",
    "INFO:__main__:  f1 = 0.8437642066979845\n",
    "INFO:__main__:  fn = 1986\n",
    "INFO:__main__:  fp = 1107\n",
    "INFO:__main__:  mcc = 0.6805204473559854\n",
    "INFO:__main__:  tn = 7726\n",
    "INFO:__main__:  tp = 8352\n",
    "\n",
    "# len = 512, bs = 4, sigmoid, with extra linear layer\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.884878201450107\n",
    "INFO:__main__:  f1 = 0.8904986355742992\n",
    "INFO:__main__:  fn = 1364\n",
    "INFO:__main__:  fp = 843\n",
    "INFO:__main__:  mcc = 0.7704622837802589\n",
    "INFO:__main__:  tn = 7990\n",
    "INFO:__main__:  tp = 8974\n",
    "\n",
    "# len = 512, bs = 4, sigmoid, WITHOUT extra linear layer\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.8852433362891868\n",
    "INFO:__main__:  f1 = 0.8914973367528113\n",
    "INFO:__main__:  fn = 1300\n",
    "INFO:__main__:  fp = 900\n",
    "INFO:__main__:  mcc = 0.770497210947315\n",
    "INFO:__main__:  tn = 7933\n",
    "INFO:__main__:  tp = 9038\n",
    "\n",
    "# len = 512, BS = 8, sigmoid, without extra linear layer\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.8658390276980856\n",
    "INFO:__main__:  f1 = 0.8702451821208756\n",
    "INFO:__main__:  fn = 1713\n",
    "INFO:__main__:  fp = 859\n",
    "INFO:__main__:  mcc = 0.734818193205147\n",
    "INFO:__main__:  tn = 7974\n",
    "INFO:__main__:  tp = 8625\n",
    "\n",
    "\n",
    "# len = 512, BS = 2, sigmoid, without extra linear layer\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.8885817119607741\n",
    "INFO:__main__:  f1 = 0.8939845145920191\n",
    "INFO:__main__:  fn = 1332\n",
    "INFO:__main__:  fp = 804\n",
    "INFO:__main__:  mcc = 0.7779384055882357\n",
    "INFO:__main__:  tn = 8029\n",
    "INFO:__main__:  tp = 9006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversarial: mix 2 arguments -> predict if mixed or not (sameside true -> reverse gradient, false -> ?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
