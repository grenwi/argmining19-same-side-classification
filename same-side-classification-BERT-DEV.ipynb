{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57523\n",
      "6380\n"
     ]
    }
   ],
   "source": [
    "# GW split\n",
    "with open(\"data/distinct_sets/within-v2.pkl\", \"rb\") as f:\n",
    "    within_train_df = pickle.load(f) # distinct\n",
    "    within_dev_df = pickle.load(f)\n",
    "    #within_train_df = pickle.load(f) # overlap\n",
    "    #within_dev_df = pickle.load(f)\n",
    "print(len(within_train_df))\n",
    "print(len(within_dev_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AH split\n",
    "if False:\n",
    "    with open(\"../argmining19-same-side-classification/data/distinct_sets/within/within_train_arg_pickle.pkl\", \"rb\") as f:\n",
    "        within_train_df = pickle.load(f)\n",
    "    with open(\"../argmining19-same-side-classification/data/distinct_sets/within/within_dev_arg_pickle.pkl\", \"rb\") as f:\n",
    "        within_dev_df = pickle.load(f)\n",
    "    tmp_all_train = set(within_train_df.argument1.tolist() + within_train_df.argument2.tolist())\n",
    "    tmp_all_dev = set(within_dev_df.argument1.tolist() + within_dev_df.argument2.tolist())\n",
    "    print(len(tmp_all_train))\n",
    "    print(len(tmp_all_dev))\n",
    "    print(len(tmp_all_train.intersection(tmp_all_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score, f1_score\n",
    "def report_training_results(y_test, y_pred):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))  \n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2))  #\n",
    "    print()\n",
    "\n",
    "    print('Report:')\n",
    "    print(classification_report(y_test, y_pred))  \n",
    "    f1_dic = {}\n",
    "    \n",
    "    f1_dic['macro'] = round(f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "    def add_tag(row):\n",
    "        title = row['topic'].lower().strip()\n",
    "        if title.find('abortion') > -1 :\n",
    "            row['tag'] = 'abortion'\n",
    "        elif title.find('gay marriage') > -1 :\n",
    "            row['tag'] = 'gay marriage'\n",
    "        else:\n",
    "            row['tag'] = 'NA'\n",
    "        return row\n",
    "\n",
    "    within_train_df = within_train_df.apply(add_tag, axis=1)\n",
    "    within_dev_df = within_dev_df.apply(add_tag, axis=1)\n",
    "    # within_test_df = within_test_df.apply(add_tag, axis=1)\n",
    "    \n",
    "    with open(\"dev_tagged_data.pkl\", \"wb\") as f:\n",
    "        # pickle.dump(cross_train_df, f)\n",
    "        # pickle.dump(cross_test_df, f)\n",
    "        pickle.dump(within_train_df, f)\n",
    "        pickle.dump(within_dev_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dev_tagged_data.pkl\", \"rb\") as f:\n",
    "    within_train_df = pickle.load(f)\n",
    "    within_dev_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_same_side  False  True \n",
      "tag                       \n",
      "abortion      17703  19011\n",
      "gay marriage   8602  12207\n",
      "\n",
      "is_same_side  False  True \n",
      "tag                       \n",
      "abortion       2303   1823\n",
      "gay marriage   1184   1070\n"
     ]
    }
   ],
   "source": [
    "print(within_train_df[[\"is_same_side\", \"tag\"]].pivot_table(index=\"tag\", columns='is_same_side', aggfunc=len))\n",
    "print()\n",
    "print(within_dev_df[[\"is_same_side\", \"tag\"]].pivot_table(index=\"tag\", columns='is_same_side', aggfunc=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formatted_dataset(df):\n",
    "    dataset = list(zip(df.argument1.tolist(), df.argument2.tolist(), df.is_same_side.tolist()))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_formatted_dataset(within_train_df)\n",
    "X_dev = get_formatted_dataset(within_dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomization experiments: \n",
    "# Exp 1: we shuffle the order of sentences in the dev set\n",
    "# Exp 2: we shuffle the order of sentences in the training set\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from random import shuffle\n",
    "\n",
    "def shuffle_sentences(text):\n",
    "    s = sent_tokenize(text)\n",
    "    shuffle(s)\n",
    "    return \" \".join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    X_dev_rnd = []\n",
    "    for item in X_dev:\n",
    "        X_dev_rnd.append((shuffle_sentences(item[0]), shuffle_sentences(item[1]), item[2]))\n",
    "    X_dev = X_dev_rnd\n",
    "\n",
    "    X_train_rnd = []\n",
    "    for item in X_train:\n",
    "        X_train_rnd.append((shuffle_sentences(item[0]), shuffle_sentences(item[1]), item[2]))\n",
    "    X_train = X_train_rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional training data from UKP SAM corpus\n",
    "* exp A: compile new training instances for 'abortion' - expect acc increase\n",
    "* exp B: compile new training instances for random other topics - expect low/no acc. increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school_uniforms.tsv 3008\n",
      "cloning.tsv 3039\n",
      "minimum_wage.tsv 2472\n",
      "nuclear_energy.tsv 3576\n",
      "abortion.tsv 3929\n",
      "gun_control.tsv 3341\n",
      "marijuana_legalization.tsv 2475\n",
      "death_penalty.tsv 3651\n",
      "25491\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "ukp_arg_path = \"data/UKP_SAM\"\n",
    "ukp_arg_files = [f for f in listdir(ukp_arg_path) if isfile(join(ukp_arg_path, f))]\n",
    "arg_df = []\n",
    "for filename in ukp_arg_files:\n",
    "    tmp_df = pd.read_csv(join(ukp_arg_path, filename), sep=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    print(filename + \" \" + str(len(tmp_df)))\n",
    "    arg_df.append(tmp_df)\n",
    "arg_df = pd.concat(arg_df)\n",
    "print(len(arg_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>retrievedUrl</th>\n",
       "      <th>archivedUrl</th>\n",
       "      <th>sentenceHash</th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "      <th>set</th>\n",
       "      <th>is_argument</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>school uniforms</td>\n",
       "      <td>http://education.newarchaeology.com/against_sc...</td>\n",
       "      <td>http://web.archive.org/web/20160817231333/http...</td>\n",
       "      <td>b095f443232cf1a6962c9ac6bf65d264</td>\n",
       "      <td>Because children are constantly growing , ther...</td>\n",
       "      <td>Argument_against</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>school uniforms</td>\n",
       "      <td>http://www.listland.com/top-10-reasons-school-...</td>\n",
       "      <td>http://web.archive.org/web/20160629081940/http...</td>\n",
       "      <td>45964f3da335c382efdf2ced6aad7a61</td>\n",
       "      <td>Critics , mostly students believe that wearing...</td>\n",
       "      <td>Argument_against</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>school uniforms</td>\n",
       "      <td>http://2016election.procon.org/view.resource.p...</td>\n",
       "      <td>http://web.archive.org/web/20170118172608/http...</td>\n",
       "      <td>f2dafb6e4c92b456c6781f27b38022f6</td>\n",
       "      <td>But I think this , I think that local communit...</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>school uniforms</td>\n",
       "      <td>http://www.listland.com/top-10-reasons-school-...</td>\n",
       "      <td>http://web.archive.org/web/20160710151116/http...</td>\n",
       "      <td>85555c58a702d2b30497b54947833cd2</td>\n",
       "      <td>People who are for uniforms say that it promot...</td>\n",
       "      <td>Argument_for</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>school uniforms</td>\n",
       "      <td>https://en.wikipedia.org/wiki/School_uniform</td>\n",
       "      <td>http://web.archive.org/web/20161209024202/http...</td>\n",
       "      <td>092006216db0a58ee854449b363d986d</td>\n",
       "      <td>^ a b Reed , Joshua B. \" Effects of a School U...</td>\n",
       "      <td>NoArgument</td>\n",
       "      <td>val</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic                                       retrievedUrl  \\\n",
       "0  school uniforms  http://education.newarchaeology.com/against_sc...   \n",
       "1  school uniforms  http://www.listland.com/top-10-reasons-school-...   \n",
       "2  school uniforms  http://2016election.procon.org/view.resource.p...   \n",
       "3  school uniforms  http://www.listland.com/top-10-reasons-school-...   \n",
       "4  school uniforms       https://en.wikipedia.org/wiki/School_uniform   \n",
       "\n",
       "                                         archivedUrl  \\\n",
       "0  http://web.archive.org/web/20160817231333/http...   \n",
       "1  http://web.archive.org/web/20160629081940/http...   \n",
       "2  http://web.archive.org/web/20170118172608/http...   \n",
       "3  http://web.archive.org/web/20160710151116/http...   \n",
       "4  http://web.archive.org/web/20161209024202/http...   \n",
       "\n",
       "                       sentenceHash  \\\n",
       "0  b095f443232cf1a6962c9ac6bf65d264   \n",
       "1  45964f3da335c382efdf2ced6aad7a61   \n",
       "2  f2dafb6e4c92b456c6781f27b38022f6   \n",
       "3  85555c58a702d2b30497b54947833cd2   \n",
       "4  092006216db0a58ee854449b363d986d   \n",
       "\n",
       "                                            sentence        annotation    set  \\\n",
       "0  Because children are constantly growing , ther...  Argument_against  train   \n",
       "1  Critics , mostly students believe that wearing...  Argument_against  train   \n",
       "2  But I think this , I think that local communit...        NoArgument  train   \n",
       "3  People who are for uniforms say that it promot...      Argument_for  train   \n",
       "4  ^ a b Reed , Joshua B. \" Effects of a School U...        NoArgument    val   \n",
       "\n",
       "   is_argument  \n",
       "0         True  \n",
       "1         True  \n",
       "2        False  \n",
       "3         True  \n",
       "4        False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collapse classes pro/con into one\n",
    "arg_df['is_argument'] = [True if a.startswith(\"Argument\") else False for a in arg_df['annotation']]\n",
    "arg_df = arg_df.dropna()\n",
    "arg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP A: select\n",
    "abortion_ukp_dataset = arg_df[arg_df[\"topic\"] == \"abortion\"][[\"sentence\", \"annotation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_pairs(dataset, n_max):\n",
    "    sentences = dataset.sentence.tolist()\n",
    "    annotations = dataset.annotation.tolist()\n",
    "    random.seed(9721)\n",
    "    rnd = list(range(n_max))    \n",
    "    random.shuffle(rnd)\n",
    "    pairs = []\n",
    "    for i, j in enumerate(rnd):\n",
    "        m = i % len(sentences)\n",
    "        n = j % len(sentences)\n",
    "        pairs.append((sentences[m], sentences[n], annotations[m] == annotations[n]))\n",
    "    return pairs\n",
    "\n",
    "additional_training_A = sample_pairs(abortion_ukp_dataset, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    X_train = X_train + additional_training_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Within topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "import random\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from transformers import (WEIGHTS_NAME, BertConfig, BertTokenizer,\n",
    "                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n",
    "                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
    "                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from utils import (convert_examples_to_features, output_modes, processors, BertForBinaryClassification, BertForSimilarityClassification)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data_dir': 'data/',\n",
    "    'model_type':  'bert',\n",
    "    'model_name': 'bert-base-uncased',\n",
    "    'task_name': 'binary',\n",
    "    'output_dir': 'outputs/',\n",
    "    'cache_dir': 'cache/',\n",
    "    'do_train': True,\n",
    "    'do_eval': True,\n",
    "    'fp16': False,\n",
    "    'fp16_opt_level': 'O1',\n",
    "    'max_seq_length': 512,\n",
    "    'output_mode': 'classification',\n",
    "    'train_batch_size': 8,\n",
    "    'eval_batch_size': 8,\n",
    "\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'num_train_epochs': 3,\n",
    "    'weight_decay': 0,\n",
    "    'learning_rate': 5e-6,\n",
    "    'adam_epsilon': 1e-9,\n",
    "    'warmup_steps': 0,\n",
    "    'max_grad_norm': 1.0,\n",
    "\n",
    "    'logging_steps': 0,\n",
    "    'evaluate_during_training': True,\n",
    "    'save_steps': 1000,\n",
    "    'eval_all_checkpoints': True,\n",
    "    'overwrite_output_dir': False,\n",
    "    'reprocess_input_data': True,\n",
    "    'notes': 'SameSide argument classification task'\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertConfig, BertForBinaryClassification, BertTokenizer),\n",
    "    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
    "    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
    "    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
    "}\n",
    "\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args['model_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /srv/home/gwiedemann/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"_num_labels\": 1,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /srv/home/gwiedemann/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(args['model_name'], num_labels=1, finetuning_task=args['task_name'])\n",
    "tokenizer = tokenizer_class.from_pretrained(args['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /srv/home/gwiedemann/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"_num_labels\": 1,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /srv/home/gwiedemann/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "INFO:transformers.modeling_utils:Weights of BertForBinaryClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForBinaryClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "model = model_class.from_pretrained(args['model_name'], num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForBinaryClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = args['task_name']\n",
    "\n",
    "processor = processors[task](X_train, X_dev)\n",
    "label_list = processor.get_labels()\n",
    "num_labels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(task, tokenizer, evaluate=False):\n",
    "    processor = processors[task](X_train, X_dev)\n",
    "    output_mode = args['output_mode']\n",
    "    \n",
    "    mode = 'dev' if evaluate else 'train'\n",
    "    cached_features_file = os.path.join(args['data_dir'], f\"cached_{mode}_{args['model_name']}_{args['max_seq_length']}_{task}\")\n",
    "    \n",
    "    if os.path.exists(cached_features_file) and not args['reprocess_input_data']:\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "               \n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", args['data_dir'])\n",
    "        label_list = processor.get_labels()\n",
    "        examples = processor.get_dev_examples(args['data_dir']) if evaluate else processor.get_train_examples(args['data_dir'])\n",
    "        \n",
    "        features = convert_examples_to_features(examples, label_list, args['max_seq_length'], tokenizer, output_mode,\n",
    "            cls_token_at_end=bool(args['model_type'] in ['xlnet']),            # xlnet has a cls token at the end\n",
    "            cls_token=tokenizer.cls_token,\n",
    "            sep_token=tokenizer.sep_token,\n",
    "            cls_token_segment_id=2 if args['model_type'] in ['xlnet'] else 0,\n",
    "            pad_on_left=bool(args['model_type'] in ['xlnet']),                 # pad on the left for xlnet\n",
    "            pad_token_segment_id=4 if args['model_type'] in ['xlnet'] else 0)\n",
    "        \n",
    "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "        torch.save(features, cached_features_file)\n",
    "        \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    # labels\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    return dataset\n",
    "\n",
    "                                        \n",
    "from pprint import pprint\n",
    "                                        \n",
    "def train(train_dataset, model, tokenizer):\n",
    "    tb_writer = SummaryWriter()\n",
    "    \n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args['train_batch_size'])\n",
    "    \n",
    "    t_total = len(train_dataloader) // args['gradient_accumulation_steps'] * args['num_train_epochs']\n",
    "    \n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=args['adam_epsilon'])\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args['warmup_steps'], num_training_steps = t_total)\n",
    "    \n",
    "    if args['fp16']:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args['fp16_opt_level'])\n",
    "        \n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args['num_train_epochs'])\n",
    "    logger.info(\"  Total train batch size  = %d\", args['train_batch_size'])\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args['gradient_accumulation_steps'])\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(args['num_train_epochs']), desc=\"Epoch\")\n",
    "    \n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "            print(\"\\r%f\" % loss, end='')\n",
    "\n",
    "            if args['gradient_accumulation_steps'] > 1:\n",
    "                loss = loss / args['gradient_accumulation_steps']\n",
    "\n",
    "            if args['fp16']:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args['max_grad_norm'])\n",
    "                \n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args['max_grad_norm'])\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "\n",
    "                global_step += 1\n",
    "\n",
    "                if args['logging_steps'] > 0 and global_step % args['logging_steps'] == 0:\n",
    "                    # Log metrics\n",
    "                    if args['evaluate_during_training']:  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results, _ = evaluate(model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar('eval_{}'.format(key), value, global_step)\n",
    "                    tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar('loss', (tr_loss - logging_loss)/args['logging_steps'], global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if args['save_steps'] > 0 and global_step % args['save_steps'] == 0:\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(args['output_dir'], 'checkpoint-{}'.format(global_step))\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, matthews_corrcoef, confusion_matrix, accuracy_score, f1_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def get_mismatched(labels, preds):\n",
    "    mismatched = labels != preds\n",
    "    examples = processor.get_dev_examples(args['data_dir'])\n",
    "    wrong = [i for (i, v) in zip(examples, mismatched) if v]\n",
    "    \n",
    "    return wrong\n",
    "\n",
    "def get_eval_report(labels, preds):\n",
    "    \n",
    "    print(labels[:15])\n",
    "    print(preds[:15])\n",
    "    \n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    f1_macro = f1_score(labels, preds, average='macro')\n",
    "    f1_micro = f1_score(labels, preds, average='micro')\n",
    "    return {\n",
    "        \"mcc\": mcc,\n",
    "        \"tp\": tp,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"acc\" : acc,\n",
    "        \"f1\" : f1,\n",
    "        \"f1_macro\" : f1_macro,\n",
    "        \"f1_micro\" : f1_micro\n",
    "    }, get_mismatched(labels, preds)\n",
    "\n",
    "def compute_metrics(task_name, preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return get_eval_report(labels, preds)\n",
    "\n",
    "def evaluate(model, tokenizer, prefix=\"\"):\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_output_dir = args['output_dir']\n",
    "\n",
    "    results = {}\n",
    "    EVAL_TASK = args['task_name']\n",
    "\n",
    "    eval_dataset = load_and_cache_examples(EVAL_TASK, tokenizer, evaluate=True)\n",
    "    if not os.path.exists(eval_output_dir):\n",
    "        os.makedirs(eval_output_dir)\n",
    "\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    \n",
    "    sigmoid_squash = torch.nn.Sigmoid()\n",
    "    cosine_squash = lambda x : (x + 1.) / 2.\n",
    "    \n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "            \n",
    "            # sigmoid output\n",
    "            logits = sigmoid_squash(logits)\n",
    "            # cosine output\n",
    "            # logits = cosine_squash(logits)\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        \n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy())\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    if args['output_mode'] == \"classification\":\n",
    "        # preds = np.argmax(preds, axis=1)\n",
    "        preds = np.round(preds).astype(int)\n",
    "    elif args['output_mode'] == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    # print(preds)\n",
    "    result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n",
    "    results.update(result)\n",
    "\n",
    "    output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return results, wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|| 57523/57523 [00:42<00:00, 1355.80it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_train_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running training *****\n",
      "INFO:__main__:  Num examples = 57523\n",
      "INFO:__main__:  Num Epochs = 3\n",
      "INFO:__main__:  Total train batch size  = 8\n",
      "INFO:__main__:  Gradient Accumulation steps = 1\n",
      "INFO:__main__:  Total optimization steps = 21573\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72423096b754b8f8d2d0a1e348a1d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add8367c62104d8982add01b88e6ce5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7191.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785541"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-1000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-1000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-2000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-2000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.553797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-3000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-3000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.118390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-4000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-4000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.521813"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-5000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-5000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.257711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-6000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-6000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.318754"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-7000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-7000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.216405\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339e4030f6d04e86824ae74b5dd6eef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7191.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.076413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-8000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-8000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.106293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-9000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-9000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008541"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-10000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-10000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000585"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-11000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-11000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-11000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.087400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-12000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-12000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.168081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-13000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-13000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-13000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.599013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-14000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-14000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-14000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d505cc263b3044fe9baf557bd19e519f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7191.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-15000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-15000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-16000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-16000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-16000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.652149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-17000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-17000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-17000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000309"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-18000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-18000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-18000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.305110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-19000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-19000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-19000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.256994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-20000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-20000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.434832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in outputs/checkpoint-21000/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/checkpoint-21000/pytorch_model.bin\n",
      "INFO:__main__:Saving model checkpoint to outputs/checkpoint-21000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: global_step = 21573, average loss = 0.25960453726561994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.004730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args['do_train']:\n",
    "    train_dataset = load_and_cache_examples(task, tokenizer)\n",
    "    global_step, tr_loss = train(train_dataset, model, tokenizer)\n",
    "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saving model checkpoint to outputs/\n",
      "INFO:transformers.configuration_utils:Configuration saved in outputs/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in outputs/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "if args['do_train']:\n",
    "    if not os.path.exists(args['output_dir']):\n",
    "            os.makedirs(args['output_dir'])\n",
    "    logger.info(\"Saving model checkpoint to %s\", args['output_dir'])\n",
    "    \n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "    model_to_save.save_pretrained(args['output_dir'])\n",
    "    tokenizer.save_pretrained(args['output_dir'])\n",
    "    torch.save(args, os.path.join(args['output_dir'], 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluate the following checkpoints: ['outputs/']\n",
      "INFO:transformers.configuration_utils:loading configuration file outputs/config.json\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"_num_labels\": 1,\n",
      "  \"architectures\": [\n",
      "    \"BertForBinaryClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file outputs/pytorch_model.bin\n",
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|| 6380/6380 [00:09<00:00, 703.33it/s] \n",
      "INFO:__main__:Saving features into cached file data/cached_dev_bert-base-uncased_512_binary\n",
      "INFO:__main__:***** Running evaluation  *****\n",
      "INFO:__main__:  Num examples = 6380\n",
      "INFO:__main__:  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f957e3e51b2407cab541b741f1bce61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=798.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results  *****\n",
      "INFO:__main__:  acc = 0.7639498432601881\n",
      "INFO:__main__:  f1 = 0.7278641127574992\n",
      "INFO:__main__:  f1_macro = 0.7597250262099149\n",
      "INFO:__main__:  f1_micro = 0.7639498432601882\n",
      "INFO:__main__:  fn = 879\n",
      "INFO:__main__:  fp = 627\n",
      "INFO:__main__:  mcc = 0.5218966148230009\n",
      "INFO:__main__:  tn = 2860\n",
      "INFO:__main__:  tp = 2014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[0 0 1 0 1 1 1 1 1 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "if args['do_eval']:\n",
    "    results = {}\n",
    "    checkpoints = [args['output_dir']]\n",
    "    #if args['eval_all_checkpoints']:\n",
    "    #    checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args['output_dir'] + '/**/' + WEIGHTS_NAME, recursive=True)))\n",
    "    #    logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "    for checkpoint in checkpoints:\n",
    "        global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n",
    "        model = model_class.from_pretrained(checkpoint)\n",
    "        model.to(device)\n",
    "        result, wrong_preds = evaluate(model, tokenizer, prefix=global_step)\n",
    "        result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())\n",
    "        results.update(result)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "distinct\n",
    "INFO:__main__:***** Eval results  *****\n",
    "INFO:__main__:  acc = 0.7639498432601881\n",
    "INFO:__main__:  f1 = 0.7278641127574992\n",
    "INFO:__main__:  f1_macro = 0.7597250262099149\n",
    "INFO:__main__:  f1_micro = 0.7639498432601882\n",
    "INFO:__main__:  fn = 879\n",
    "INFO:__main__:  fp = 627\n",
    "INFO:__main__:  mcc = 0.5218966148230009\n",
    "INFO:__main__:  tn = 2860\n",
    "INFO:__main__:  tp = 2014\n",
    "\n",
    "overlap\n",
    "INFO:__main__:***** Eval results  *****\n",
    "INFO:__main__:  acc = 0.7365933840147935\n",
    "INFO:__main__:  f1 = 0.6767523953605649\n",
    "INFO:__main__:  f1_macro = 0.7272458232003934\n",
    "INFO:__main__:  f1_micro = 0.7365933840147934\n",
    "INFO:__main__:  fn = 685\n",
    "INFO:__main__:  fp = 597\n",
    "INFO:__main__:  mcc = 0.4549951305479221\n",
    "INFO:__main__:  tn = 2243\n",
    "INFO:__main__:  tp = 1342"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# AH dev split\n",
    "--------------\n",
    "# Exp1: baseline, bs = 8, seqlen = 512\n",
    "\n",
    "INFO:__main__:***** Eval results 8000 *****\n",
    "INFO:__main__:  acc = 0.6142410015649452\n",
    "INFO:__main__:  f1 = 0.6414545454545455\n",
    "INFO:__main__:  fn = 245\n",
    "INFO:__main__:  fp = 248\n",
    "INFO:__main__:  mcc = 0.2240184986717707\n",
    "INFO:__main__:  tn = 344\n",
    "INFO:__main__:  tp = 441\n",
    "\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.6103286384976526\n",
    "INFO:__main__:  f1 = 0.6359649122807017\n",
    "INFO:__main__:  fn = 251\n",
    "INFO:__main__:  fp = 247\n",
    "INFO:__main__:  mcc = 0.21678499365930243\n",
    "INFO:__main__:  tn = 345\n",
    "INFO:__main__:  tp = 435\n",
    "\n",
    "# Exp2: shuffling of sentences in training set\n",
    "INFO:__main__:***** Eval results 5000 *****\n",
    "INFO:__main__:  acc = 0.5978090766823161\n",
    "INFO:__main__:  f1 = 0.6302158273381295\n",
    "INFO:__main__:  fn = 248\n",
    "INFO:__main__:  fp = 266\n",
    "INFO:__main__:  mcc = 0.1896309041932604\n",
    "INFO:__main__:  tn = 326\n",
    "INFO:__main__:  tp = 438\n",
    "\n",
    "# GW dev set split (train: 42k, dev 20k)\n",
    "# --------------------------------------\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.6323781306420999\n",
    "INFO:__main__:  f1 = 0.5862122870095356\n",
    "INFO:__main__:  fn = 3568\n",
    "INFO:__main__:  fp = 4373\n",
    "INFO:__main__:  mcc = 0.25726611965853796\n",
    "INFO:__main__:  tn = 8035\n",
    "INFO:__main__:  tp = 5625\n",
    "\n",
    "# GW dev set split (train: 20k, dev 42k)\n",
    "# --------------------------------------\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.5161458087088081\n",
    "INFO:__main__:  f1 = 0.5783271528636177\n",
    "INFO:__main__:  fn = 10882\n",
    "INFO:__main__:  fp = 9586\n",
    "INFO:__main__:  mcc = 0.01175182735489496\n",
    "INFO:__main__:  tn = 7798\n",
    "INFO:__main__:  tp = 14036\n",
    "\n",
    "\n",
    "# COSINE TARGET\n",
    "# ======================================\n",
    "\n",
    "# GW dev set split (train: 20k, dev 42k)\n",
    "# --------------------------------------\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.5438986336343435\n",
    "INFO:__main__:  f1 = 0.6419212352919342\n",
    "INFO:__main__:  f1_macro = 0.5069511130564222\n",
    "INFO:__main__:  f1_micro = 0.5438986336343435\n",
    "INFO:__main__:  fn = 7624\n",
    "INFO:__main__:  fp = 11670\n",
    "INFO:__main__:  mcc = 0.02406836140845892\n",
    "INFO:__main__:  tn = 5714\n",
    "INFO:__main__:  tp = 17294\n",
    "\n",
    "# GW dev set split (train: 42k, dev 20k)\n",
    "# --------------------------------------\n",
    "INFO:__main__:***** Eval results 14000 *****\n",
    "INFO:__main__:  acc = 0.43261886023795193\n",
    "INFO:__main__:  f1 = 0.5941453076362673\n",
    "INFO:__main__:  f1_macro = 0.32583303523923485\n",
    "INFO:__main__:  f1_micro = 0.43261886023795193\n",
    "INFO:__main__:  fn = 222\n",
    "INFO:__main__:  fp = 12034\n",
    "INFO:__main__:  mcc = 0.018090137613471058\n",
    "INFO:__main__:  tn = 374\n",
    "INFO:__main__:  tp = 8971\n",
    "\n",
    "# (u,v,|u-v|) SIGMOID TARGET\n",
    "# ======================================\n",
    "# GW dev set split (train: 42k, dev 20k)\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.5023166753344995\n",
    "INFO:__main__:  f1 = 0.5262068189490267\n",
    "INFO:__main__:  f1_macro = 0.501048093185833\n",
    "INFO:__main__:  f1_micro = 0.5023166753344995\n",
    "INFO:__main__:  fn = 13227\n",
    "INFO:__main__:  fp = 7826\n",
    "INFO:__main__:  mcc = 0.018747173537467233\n",
    "INFO:__main__:  tn = 9558\n",
    "INFO:__main__:  tp = 11691\n",
    "\n",
    "# GW dev set split (train: 20k, dev 42k)\n",
    "INFO:__main__:***** Eval results outputs *****\n",
    "INFO:__main__:  acc = 0.561362899865747\n",
    "INFO:__main__:  f1 = 0.3238421465781774\n",
    "INFO:__main__:  f1_macro = 0.4996167805760804\n",
    "INFO:__main__:  f1_micro = 0.561362899865747\n",
    "INFO:__main__:  fn = 6924\n",
    "INFO:__main__:  fp = 2551\n",
    "INFO:__main__:  mcc = 0.04895628334054007\n",
    "INFO:__main__:  tn = 9857\n",
    "INFO:__main__:  tp = 2269"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# With additional UKP training data (5000 pairs of topic: abortion)\n",
    "INFO:__main__:***** Eval results  *****\n",
    "INFO:__main__:  acc = 0.6374704874774316\n",
    "INFO:__main__:  f1 = 0.5810731289787621\n",
    "INFO:__main__:  f1_macro = 0.6307789244387874\n",
    "INFO:__main__:  f1_micro = 0.6374704874774316\n",
    "INFO:__main__:  fn = 3762\n",
    "INFO:__main__:  fp = 4069\n",
    "INFO:__main__:  mcc = 0.26181941650594354\n",
    "INFO:__main__:  tn = 8339\n",
    "INFO:__main__:  tp = 5431\n",
    "\n",
    "# Without additional UKP training data (topic: abortion)\n",
    "INFO:__main__:***** Eval results  *****\n",
    "INFO:__main__:  acc = 0.6543215591870747\n",
    "INFO:__main__:  f1 = 0.5924349107581465\n",
    "INFO:__main__:  f1_macro = 0.646163197109711\n",
    "INFO:__main__:  f1_micro = 0.6543215591870747\n",
    "INFO:__main__:  fn = 3766\n",
    "INFO:__main__:  fp = 3701\n",
    "INFO:__main__:  mcc = 0.2923385001628381\n",
    "INFO:__main__:  tn = 8707\n",
    "INFO:__main__:  tp = 5427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my apologies for not posting definitions. if that\\'s how you want to do this, fine by me. but debating morals is not foolish. what is foolish is believing that morals are only subjective- then we have the argument \"what is right for you may not be right for me\", and there is a whole lot of vague and deliberately blurred points in that itself. in terms of definitions, \"wrong\" is better defined not by synonyms that only express part of it, but by a true definition, such as \"not in accordance with what is morally right or good\", or \"not correct in action, judgement, opinio, method, etc\" (www.dictionary.com/browse/wrong). now, there is one theme that you have carried through your entire argument so far that i wish to address- the assertion that a foetus is not human or alive. both of these are wrong- incorrect in judgement and opinion- and i must repeat myself that a foetus has to be human. it is a part of our species, and the mere fact that it is less developed and may only be a small number of cells does not change this. there are single-celled organisms out there that are still part of a species. a human is a human, whether still undeveloped or not. if you wish to argue by way or definitions, i will give you the accepted definition of a species: \"two or more organisms that can reproduce together to produce viable offspring.\" therefore we have a species, made up those old enough to reproduce, and those who are not- the one who are not old enough to reproduce (typically those humans under the age of eleven or so) are still considered viable offspring. therefore i can safely conclude that a human foetus/baby is human, as it is part of our species. it is certainly not part of some other species. and that you say it is not alive- i\\'ve already explained in my first argument why it is alive. if we are still playing the definition game, i\\'ll define alive for you: \"having life; living; existing; not dead or lifeless\" (www.dictionary.com/browse/alive). it is quite clear that a foetus is not dead- it is growing and developing more all the time, which only things that are alive can do. i have never seen a dead thing grow. have you? now, as for needing its mother for growth, well of course it does! what baby doesn\\'t? what is the purpose of a mother, if not to cherish and nurture her offspring and to raise them up to be independent? plants rely on the sun for growth. baby animals rely on their mothers. human children rely on their parents both. i\\'m not sure why something needs to reproduce to be alive, that\\'s like implying a three year old isn\\'t alive. also, your statement, \"i believe a foetus is alive later in a pregnancy\". on what grounds do you believe this? because the baby has started to look a bit more like your idea of a human? \"it is obvious a foetus is not a human...foetuses can\\'t think, stand upright, or live on their own.\" indeed. have you ever seen a newborn creature of any species? they cannot do those things either, but does that classify them as something other than part of that species? please take a biology class. as i have clarified that a foetus is, indeed, alive and human, i do not need to defend myself to your arguments that abortion is not murder. your own definition, \"the unlawful premeditated killing of one human being by another\", supports this. abortion is not legal everywhere, so the \"unlawful\" part is still debatable i suppose, but it fits the criteria nonetheless. \"the foetus cannot feel pain. it can\\'t think. it isn\\'t conscious. when you abort it, you are not killing a human.\" by week 6, the baby already has blood pumping through its heart. by week 7, the neural tube is already developing, and in week 8, the brain has already divided into three parts and is growing rapidly. the baby has movement and is even starting to look human, despite being so tiny (about 0.6 inches, 0.04 ounces)! since we have ascertained already that a human brain is not fully developed until 25 years of age, i thought i\\'d let you know when it starts to develop. you said abortion usually occurs before 28 weeks, but what really happens during that time? in only seven weeks counted towards due date- which is just five weeks since conception!- the brain is already developing. thumb sucking begins in week 12 (www.parents.com/pregnancy/stages/fetal-development/first-trimester-images-of-your-developing-baby/). \"a four year old can live on its own.\" untrue. good luck having a four year old survive without its parents. it may be able to physically shovel food into its mouth alone, but what four year old can provide its own food, its own home, manage its own health and hygiene, and all the other things a really independent human being can do? a four year old is barely less helpless than a foetus/baby. \"people don\\'t abort the foetus for fun. they do it to help the foetus.\" again, incorrect. they do it because they do not want the responsibility that comes with being a parent, or because they don\\'t think they can handle it financially. the majority of abortions are performed because people think they can\\'t handle it financially, but there is this wonderful thing that has been around longer than abortion- adoption. it happens even in nature, and it is certainly more likely to help a foetus than killing it. single parents are not a reason to abort the baby. i know plenty of single parents who have kept the baby and still managed. a partner isn\\'t the only way to keep a baby- many of those women would have family who would be happy to help them out. also, most of the women getting abortions do not know the risks. they have been led to believe that childbirth is more dangerous and that abortion is \"okay\". if they were shown the statistics of abortion-related deaths compared to child-birth related deaths, they\\'d most likely be surprised. abortion doctors have mandated quotas. they cannot afford to inform every woman looking for an answer. abortion is legal because of all the women who threatened to kill themselves to their psychologists/therapists if they couldn\\'t have an abortion. they would say the right things, get written permission, and go have the abortion. now it\\'s legal, and more people are doing it who would have been fine without it. suicide and depression are more common among those who aborted than those who didn\\'t. it\\'s a fact. it has been studied many times. what if the foetus will die when it\\'s born? it still has a better chance of survival than if it was aborted. what if the mother will die when she gives birth? the chances of that are one in ten thousand, as i\\'ve said, but still, there are no certainties except that abortion kills the child and is more likely to kill the mother than childbirth. what if the girl is young? surprisingly, this does not change anything. girls as young as twelve have successfully had children. girls as young as that have also, in the face of having been raped, been amazingly brave and said that they would rather have the child than abort it. twelve year old girls can change the world. rape is not a good enough reason. an abortion won\\'t change the fact that they were raped. they can give the child up for adoption. abortion will only make things worse. besides, why punish a child for the crimes of its father? don\\'t kill the baby, punish the rapist so it doesn\\'t happen again. if the woman cannot support the child financially and it is actually a problem- adoption. i\\'ve said it before. there are kids who protest again abortion and they have signs that say \"i\\'m so glad i was adopted instead of aborted\". what can you say to that kid? \"you should be dead\"? \"every child a wanted child\"? \"you\\'re not important enough for your mother to die for\"? being a mother will not ruin one\\'s life. it is a blessing. it is a privilege worth fighting for. if a woman is willing to kill her baby, she doesn\\'t deserve it. i believe i have answered each of your arguments. i have proven a foetus is human and alive, therefore nullifying several of your arguments. i have also explained why i think abortion should not be allowed at all. i await your next installment in the debate.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_preds[0].text_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
